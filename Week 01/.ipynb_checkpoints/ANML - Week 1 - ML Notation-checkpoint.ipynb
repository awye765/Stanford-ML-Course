{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1: Machine Learning Notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. A starting hypothesis\n",
    "\n",
    "In most machine learning problems we can describe the high level process as follows:\n",
    "\n",
    "<img src=\"../Images\\H6qTdZmYEeaagxL7xdFKxA_2f0f671110e8f7446bb2b5b2f75a8874_Screenshot-2016-10-23-20.14.58.png\" width=30%>\n",
    "\n",
    "This is showing that we take a dataset, pass it into the appropriate learning algorithm to generate the necessary hypothesis that is able to accurately produce an output $y$ for a given input $x$.  The starting hypothesis is usually described as:\n",
    "\n",
    "\\begin{align}\n",
    "h_\\theta(x) = \\theta_0 + \\theta_1 x\n",
    "\\end{align}\n",
    "\n",
    "whereby this means what function of x (i.e. $h_\\theta)$)  most closely produces the correct output $y$.  $\\theta_0$ and $\\theta_1$ are constants (aka \"weights\" or \"parameters\" as used in the context of machine learning). In most machine learning problems our goal is to find the perfect values of $\\theta_0$ and $\\theta_1$ to make our hypothesis as accurate as possible in terms of producing the correct output $y$ for a given $x$ input.\n",
    "\n",
    "As machine learning problems become more complex, the relevant mathematical representations and corresponding notation necessary to describe each model becomes increasingly complicated.\n",
    "\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. More complex notation\n",
    "\n",
    "The below table summarises most of the common notation used in most basic machine learning functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../Images/notationSummary.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In context, the notation used to describe samples and features is demonstrated below against some mock data:\n",
    "\n",
    "<img src=\"../Images/multivariateNotation.png\"/> \n",
    "\n",
    "<b>Note:</b> $n + 1$ denotes that the features are $n + 1$ dimensional in the sense there are $n$ number of features plus a constant = 1, which is the bias unit.  This is explained in later notebooks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
