{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1: Matrices & Vectors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Linear Algebra\n",
    "\n",
    "## 1.1. What is linear algebra?\n",
    "\n",
    "### 1.1.1. High level idea\n",
    "\n",
    "\"<b>Algebra</b>\" means \"relationships\" and \"<b>linear</b>\" means \"line-like\", therefore linear algebra is all about <b>line-like relationships</b>.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2. What is the difference between 'linear' and 'non-linear' alegbra?\n",
    "\n",
    "Linear relationships are <b>straight</b> whereas non-linear relationships are <b>not straight</b>:\n",
    "\n",
    "<img src=\"../Images\\linearNonlinear.png\" width=60%>\n",
    "\n",
    "Linear relationships are <b>predictable</b> whereas non-linear relationships are <b>not predictable</b>:\n",
    "\n",
    "1. A pyramidal roof is linear: move forward 3 horizontal feet (relative to the ground) and you might rise 1 foot in elevation (i.e. the slope! Rise/run = 1/3). Move forward 6 feet, and you’d expect a rise of 2 feet. \n",
    "\n",
    "\n",
    "2. A dome is non-linear: each horizontal foot forward raises you a different amount.\n",
    "\n",
    "\n",
    "3. The benefit of (1) is predictability.  For instance, if we measure the relationship between feet forward ($x$) and raise upward ($y$):\n",
    "\n",
    " a. If 3 feet forward has a 1-foot rise, then going 10x as far forward ($10\\cdot x$) should give a 10x higher rise ($10\\cdot y$), i.e. 30 feet forward is a 10-foot rise.\n",
    " \n",
    " b. If 3 feet forward has a 1-foot rise, and 6 feet forward ($6\\cdot x$) has a 2-foot rise ($2\\cdot y$), then (3 + 6) feet should have a (1 + 2) foot rise.\n",
    " \n",
    " c. In math terms, an operation $F$ is linear if <b>scaling inputs scales the output, and adding inputs adds the outputs</b>:\n",
    "\n",
    "\\begin{align*}\n",
    "F(ax) &= a \\cdot F(x) \\\\\n",
    "F(x + y) &= F(x) + F(y)\n",
    "\\end{align*}\n",
    "\n",
    "4. In our example, $F(x) = y$ calculates the rise when moving forward $x$ feet, and the properties hold:\n",
    "\n",
    "\\begin{align*}\n",
    "F(10\\cdot 3) &= 10\\cdot F(3) = 10\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "F(3 + 6) &= F(3) + F(6) = 3\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3. So where do matrices and vectors come in?\n",
    "\n",
    "Matrices and vectors are structures representing the various inputs, operaitons and outputs for linear functions.  These structures allow us to:\n",
    "\n",
    "1. Store data;\n",
    "\n",
    "\n",
    "2. Track data; and\n",
    "\n",
    "\n",
    "3. Tranform data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4. A very simple example of how matrices can be used to calculate linear functions\n",
    "\n",
    "Assume we have:\n",
    "\n",
    "1. <b>Input data:</b> 2 x stock portfolios, one for each of Alice and Bob, with their total holdings for shares in Apple, Google and Microsoft, i.e.\n",
    "\n",
    "Name | Apple | Google | Microsoft\n",
    "--- | --- | --- | ---\n",
    "Alice | 1000 | 1000 | 1000\n",
    "Bob | 500 | 2000 | 500\n",
    "\n",
    "<br>\n",
    "<center>Presented as a matrix:</center>\n",
    "<br>\n",
    "\n",
    "<p style='text-align: center;'> \n",
    "$I = \\begin{bmatrix}\n",
    "1000 & 1000 & 1000\\\\500 & 2000 & 500\n",
    "\\end{bmatrix}$\n",
    "</p>\n",
    "\n",
    "\n",
    "2. <b>Operations:</b> the changes in company values for each of Apple (a 20% increase), Google (a 5% decrease) and Microsoft (no change) after a news event;\n",
    "\n",
    "Company | Increase | Decrease | No Change\n",
    "--- | --- | --- | ---\n",
    "Apple | 1.2 | 0 | 0\n",
    "Google | 0 | 0.95 | 0\n",
    "Microsoft | 0 | 0 | 1\n",
    "Overall Profit | .20 | -0.05 | 0\n",
    "\n",
    "<br>\n",
    "<center>Presented as a matrix:</center>\n",
    "<br>\n",
    "\n",
    "<p style='text-align: center;'> \n",
    "$O = \\begin{bmatrix}\n",
    "1.2 & 0 & 0\\\\0 & 0.95 & 0\\\\ 0 & 0 & 1\\\\0.20 & -0.05 & 0\n",
    "\\end{bmatrix}$\n",
    "</p>\n",
    "\n",
    "3. <b>Output:</b> updated portfolios for each of Alice and Bob, which will include a bonus output - the net profit / loss from the event.\n",
    "\n",
    "\n",
    "4. To calculate (3), we need to multiply the operations ($O$) by the inputs ($I$).  As $O$ is 4 x 3 dimensional and $I$ is 2 x 3 dimensional we cannot multiply \"as is\". This is because the number of columns of matrix $a$ must match the number of rows of matrix $b$.  \n",
    "\n",
    "\n",
    "5. To match up $O$ and $I$ to enable matrix multiplication we can <b>transpose</b> $I$, i.e. swap its rows and columns so that rows become columns and columns become rows.  The transposition of $I$ is denoted by the $^{T}$:\n",
    "\n",
    "<p style='text-align: center;'> \n",
    "$I = \\begin{bmatrix}\n",
    "1000 & 1000 & 1000\\\\500 & 2000 & 500\n",
    "\\end{bmatrix}^{T}$\n",
    "</p>\n",
    "\n",
    "<br>\n",
    "<center>becomes</center>\n",
    "<br>\n",
    "\n",
    "<p style='text-align: center;'> \n",
    "$I = \\begin{bmatrix}\n",
    "1000 & 500\\\\ 1000 & 2000\\\\ 1000 & 500\n",
    "\\end{bmatrix}$\n",
    "</p>\n",
    "\n",
    "\n",
    "\n",
    "6. Therefore, this now means we can complete the calculation described in (4) to achieve the outcome described in (3):\n",
    "\n",
    "<p style='text-align: center;'> \n",
    "$\\begin{equation}\n",
    "    \\begin{bmatrix}\n",
    "    1.2 & 0 & 0\\\\0 & 0.95 & 0\\\\ 0 & 0 & 1\\\\0.20 & -0.05 & 0\n",
    "    \\end{bmatrix}\n",
    "    \\cdot\n",
    "   \\begin{bmatrix}\n",
    "   1000 & 500\\\\ 1000 & 2000\\\\ 1000 & 500\n",
    "   \\end{bmatrix}\n",
    "    =\n",
    "    \\begin{bmatrix}\n",
    "1200 & 600\\\\ 950 & 1900\\\\ 1000 & 500\\\\ 150 & 0\n",
    "\\end{bmatrix}\n",
    "\\end{equation}$ \n",
    "</p>\n",
    "\n",
    "\n",
    "6. Which in tabular form can be presented as:\n",
    "\n",
    "Name | Apple | Google | Microsoft | Profit / Loss\n",
    "--- | --- | --- | --- | ---\n",
    "Alice | 1200 | 950 | 1000 | 150\n",
    "Bob | 600 | 1900 | 500 | 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3. High level relationship with machine learning\n",
    "\n",
    "For machine learning the key takeaway is this:\n",
    "\n",
    "1. linear algebra gives you mini-spreadsheets to represent your maths equations, including their inputs, operations and outputs.\n",
    "\n",
    "    and\n",
    "\n",
    "\n",
    "2. in turn this enables you to manipulate large groups of data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4. Useful Resources\n",
    "\n",
    "A great intuition regarding general linear algebra in more detail can be found [here](https://betterexplained.com/articles/linear-algebra-guide/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. How is linear algebra relevant to machine learning?\n",
    "\n",
    "As explained above, linear algebra allows us to store, track and transform data in turn allowing us to perform complex equations with data simultaneously and efficiently. The principal tools most relevant to machine learning are:\n",
    "\n",
    "  <img src=\"../Images\\scalarVectorMatrix.png\" width=60%>\n",
    "\n",
    "<b>Vectors</b> and <b>Matrices</b> (as explored in this notebook) are used to represent data, including:\n",
    "\n",
    "1. input variables $x$;\n",
    "\n",
    "    \n",
    "2. output variables $y$; \n",
    "\n",
    "    \n",
    "3. weights (aka parameters and coefficients) $\\theta$; and\n",
    "\n",
    "    \n",
    "4. operations, e.g. addition ($x + y$), subtraction ($x - y$), multiplcation ($x x y$), division ($x / y$), inversion ($x^{-1}$), transposition ($x^{T}$) and so on).\n",
    "\n",
    "And in doing so, allow complex computations to be performed simultaneously and efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. What are they?\n",
    "\n",
    "A matrix:\n",
    "\n",
    "1. Is an ordered <b>array of numbers</b>, e.g. $\\left\\lgroup \\matrix{1 & 2\\cr 3 & 4} \\right\\rgroup$; \n",
    "\n",
    "    and\n",
    "    \n",
    "    \n",
    "2. Has <b>two indices</b>, the first one points to a <b>row</b> and the second points to a <b>column</b>.  See below notation regarding how to express the correct indices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Notation\n",
    "\n",
    "Matrices notation is as follows:\n",
    "\n",
    "1. Matrices are described by their dimensions: number of rows x number of columns, i.e. R<sup>[rows x columns]</sup>.  This is often represented in terms of $m$ rows and $n$ columns.  For example, R<sup>4 x 2</sup> means a matrix with x 4 rows and x 2 columns, e.g. \n",
    "\n",
    "<p style='text-align: center;'> \n",
    "$\\begin{bmatrix}\n",
    "1 & 2\\\\3 & 4\\\\ 5 & 6 \\\\ 7 & 8\n",
    "\\end{bmatrix}$\n",
    "</p>\n",
    "\n",
    "\n",
    "2. Matrix elements are identified like this: $A_\\text{(i, j)}$, where:\n",
    "\n",
    "  (a) i = the i<sup>th</sup> <b>row</b>; and\n",
    "\n",
    "  (b) j = the j<sup>th</sup> <b>column</b>.\n",
    "\n",
    "  e.g. the below, which is an R<sup>4 x 2</sup> matrix:\n",
    "\n",
    "  <p align = \"center\">\n",
    "  <img src=\"../Images\\matrix1.png\" width=60%>\n",
    "  </p>\n",
    "\n",
    "3. Matrices usually denoted by an <b>uppercase</b> letter like in the above image.  When referring to a matrix of features we used the capital letter, e.g. $A$ in the above example, and when referring to a particular feature within the matrix we either identify it specifically, e.g. <b>A<sub>1, 1</sub></b>, or generally with the lower case letter, e.g. $a$ in the above example.\n",
    "\n",
    "\n",
    "4. $A^{T}$ indicates the <b>transpose</b> of the matrix (explained in more detail below).\n",
    "\n",
    "\n",
    "5. $A^{-1}$ indicates the <b>inverse</b> of a matrix (explained in more detail below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Vectors\n",
    "\n",
    "## 3.1. What are they?\n",
    "\n",
    "A vector:\n",
    "\n",
    "1. Is an ordered array of numbers and can be either: \n",
    "\n",
    "    (a) a column, in which case it is a $n \\text{ x } 1$ matrix because it always has $1$ column and some number ($n$) of rows:\n",
    "    \n",
    "    <p style='text-align: center;'> \n",
    "    $\\begin{bmatrix}\n",
    "    1 \\\\2 \\\\ 3\n",
    "    \\end{bmatrix}$\n",
    "    </p>\n",
    "    \n",
    "    <br><center>or</center>\n",
    "    \n",
    "    (b) a row, in which case it is a $1 \\text{ x } n$ matrix becauseit always has $1$ row and some number ($n$) of columns:\n",
    "    \n",
    "    <p style='text-align: center;'> \n",
    "    $\\begin{bmatrix}\n",
    "    1 & 2 & 3\n",
    "    \\end{bmatrix}$\n",
    "    </p>\n",
    "    \n",
    "2. Is <b>Single indexed</b>, i.e. because of the <b>one dimensionality</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Notation\n",
    "\n",
    "1. Vector elements are identified like this: $v_{(i)}$, where $i$ = the $i^{th}$ <b>row</b> (if a column vector) or <b>column</b> (if a row vector).\n",
    "\n",
    "\n",
    "2. Some vectors are <b>1-indexed</b> (i.e. index starts at 1), but others are <b>0-indexed</b> (i.e. index starts at 0).\n",
    "\n",
    "\n",
    "3. Unlike matrices, vectors usually denoted by an <b>lowercase</b> letter.\n",
    "\n",
    "## 3.3. Useful Resources\n",
    "\n",
    "- https://study.com/academy/lesson/difference-between-a-row-column-vector.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Operations\n",
    "\n",
    "## 4.1. Intro\n",
    "\n",
    "Matrices and vectors can be added, subtracted, multiplied, divided, inverted and transposed.  I've not made many of my own notes as other people have detailed and diagrammed this already in concise but comprehensive fashion - see links where referenced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Addition, Subtraction, Negatives, Division, Multiplication (Constant) & Transposition\n",
    "\n",
    "See [here](https://www.mathsisfun.com/algebra/matrix-introduction.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Multiplication (of Matrices)\n",
    "\n",
    "### 4.2.1. Generally\n",
    "\n",
    "See [here](https://www.mathsisfun.com/algebra/matrix-multiplying.html).  The two most important rules are:\n",
    "\n",
    "### 4.2.2. The most important point\n",
    "\n",
    "1. The number of <b>columns of the 1st matrix must equal the number of rows of the 2nd matrix</b>.\n",
    "\n",
    "\n",
    "    and\n",
    "    \n",
    "\n",
    "2. The result will have:\n",
    "\n",
    "    (a) the <b>same number of rows as the 1st matrix</b>; and \n",
    "    \n",
    "    (b) the <b>same number of columns as the 2nd matrix</b>.\n",
    "\n",
    "In other words, <b>dimensionality</b> of the underlying matrices matters! See further below.\n",
    "\n",
    "### 4.2.3. Order of Multiplication\n",
    "\n",
    "In arithmetic multiplication is <b>\"Commutative\"</b>, that is to say: 3 x 5 = 5 x 3.  This is not generally true of matrices where: AB ≠ BA. In other words, changing the order of multiplication usually changes the result:\n",
    "\n",
    "<p align = \"center\">\n",
    "  <img src=\"../Images\\orderOfMultiplication.png\" width=40%>\n",
    "  </p>\n",
    "\n",
    "### 4.2.4. Identity Matrix\n",
    "\n",
    "The <b>\"Identity Matrix\"</b> is the <b>matrix equivalent</b> of the number $1$.  Concretely this the identity matrix has the following properties:\n",
    "\n",
    "1. It is \"square\", i.e. has same number of rows as columns).\n",
    "\n",
    "\n",
    "2. It can be large or small, i.e. 2×2, 100×100, ... whatever).\n",
    "\n",
    "\n",
    "3. It has 1s on the diagonal and 0s everywhere else:\n",
    "\n",
    "  <p align = \"center\">\n",
    "  <img src=\"../Images\\identityMatrix.gif\" width=20%>\n",
    "  </p>\n",
    "\n",
    "\n",
    "4. Its symbol is the capital letter $I$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Inversion\n",
    "\n",
    "See [here](https://www.mathsisfun.com/algebra/matrix-inverse.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. Order of Operations\n",
    "\n",
    "1. Multiplication\n",
    "2. Division\n",
    "3. Addition\n",
    "4. Subtraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5. Useful Resources\n",
    "\n",
    "- https://www.mathsisfun.com/algebra/systems-linear-equations.html\n",
    "\n",
    "- https://www.mathsisfun.com/algebra/linear-equations.html\n",
    "\n",
    "- https://www.mathsisfun.com/algebra/matrix-introduction.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Dimensionality is Paramount!\n",
    "\n",
    "## 5.1. Why is dimensionality important?\n",
    "\n",
    "Dimensionality is <b>paramount</b> because it determines both: \n",
    "\n",
    "1. Whether two matrices can be multipled together \"as is\", i.e. as they are currently organised, either with features as columns and samples as rows or vice versa.\n",
    "\n",
    "\n",
    "2. If the answer to (1) is \"no\", the existing dimensionality will inform how we go about fixing the dimensionality to enable multiplication of those two matrices.\n",
    "\n",
    "3. However, where dimensionality permits multiplication this does not necessarily mean it produces the correct results for our hypothesis.  E.g. see the below examples as to where this can go wrong!\n",
    "\n",
    "See below regarding the different options for univariate and multivariate linear regression and distinction between multiplying a single sample $x^{(i)}$ by $\\theta$ values or the entire matrix $X$ of all samples by $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Dimensionality Options\n",
    "\n",
    "### 5.2.1. In General\n",
    "\n",
    "Features and samples can be arranged in two different dimensions:\n",
    "    \n",
    "  <p align = \"center\">\n",
    "  <img src=\"../Images\\featuresAsColumnsOrRows.png\" width=80%>\n",
    "  </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2. Conventions used in Andrew Ng's Introduction to Machine Learning course\n",
    "\n",
    "The Andrew Ng course, Introduction to Machine Learning, when multiplying a single sample of features by corresponding $\\theta$ values, favours matrices with <b>features arranged as rows</b> and <b>samples arranged as columns</b>.  \n",
    "\n",
    "However, it's very easy to become confused for several reasons.  These are as follows.\n",
    "\n",
    "#### Confusion 1 - Table Data (features as columns) vs. Sample Vector (features as rows)\n",
    "\n",
    "The Andrew Ng course routinely introduces datasets via tabular presentations for the examples.  E.g. the below with <b>features as columns</b> and <b>samples as rows</b>:\n",
    "\n",
    "  <p align = \"center\">\n",
    "  <img src=\"../Images\\multivariateNotation.png\" width=80%>\n",
    "  </p>\n",
    "  \n",
    "However, when computing the hypothesis for a single sample, the sample data for $x^{(i)}$ is organised with <b>features as rows</b> in a single column vector.  For instance, the sample $x^{1}$ is arranged as an $(n + 1)$ x $1$ column vector like so:\n",
    "\n",
    "<p style='text-align: center;'> \n",
    "$x^{1} = \\begin{bmatrix}\n",
    "1 \\\\2104 \\\\5 \\\\ 1 \\\\45\n",
    "\\end{bmatrix}$\n",
    "</p>\n",
    "\n",
    "And likewise, the $\\theta$ values is arranged as an $(n + 1)$ x $1$ column vector like so:\n",
    "\n",
    "<p style='text-align: center;'> \n",
    "$\\theta = \\begin{bmatrix}\n",
    "1 \\\\2 \\\\3 \\\\ 4 \\\\5\n",
    "\\end{bmatrix}$\n",
    "</p>\n",
    "\n",
    "This caused me confusion because I intuitively began representing samples as rows and features as columns, probably because this logically follows the form of the table layout.  Doing so means it's very easy to then get dimensionality mixed up, and in turn the solutions to fix dimensionality problems are likewise confused."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion 2 - numpy.matrix (features as columns) vs. Andrew Ng Sample Vector (features as rows)\n",
    "\n",
    "In various python implementations of the coding exercises, including the one I've adapted, numpy matrices are often used to organise the input variables $x$ and the $\\theta$ values.  However, it took me some time to appreciate that used this way, numpy matrices organise features as columns and samples as rows vs. the Andrew Ng course's orientation, i.e. samplees as columns and features as rows.  For instance:\n",
    "\n",
    "1. Create a numpy.matrix of the X values like so: `X = np.matrix(X.values)`\n",
    "\n",
    "\n",
    "2. Doing so organises the samples into rows and features into columns like so: `X[1]` returns `matrix([[1.    , 2104    , 5    , 1    , 45]])`\n",
    "\n",
    "\n",
    "3. The same applies if the $\\theta$ values are organised in a numpy matrix, e.g. `matrix([[1.    , 2    , 3    , 4    , 5]])`\n",
    "\n",
    "This caused confusion when jumping between my python implementations and Andrew Ng's course materials, including the MatLab/OCTAVE coding exercises.  The key difference being that if using numpy matrices per the above, it's necessary to <b>transpose</b> the $\\theta$ row vector into a column vector to ensure correct dimensionality and allow matrix multiplication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Univariate Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1. The Hypothesis\n",
    "\n",
    "$h_\\theta(x) = \\theta_0 + \\theta_1x_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2. The Data & Theta Values\n",
    "\n",
    "$\\theta_0 = -40$ and $\\theta_1 = 0.25$.\n",
    "\n",
    "<img src=\"../Images\\univariateLinRegData.png\" width=40%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.3. Single Sample\n",
    "\n",
    "#### How the data and $\\theta$ values are arranged\n",
    "\n",
    "In Andrew Ng's course, a single sample for univariate linear regression is presented as a $1$ x $1$ dimensional column vector:\n",
    "\n",
    "<p style='text-align: center;'> \n",
    "$x^{1} = \\begin{bmatrix}\n",
    "2104\n",
    "\\end{bmatrix}$\n",
    "</p>\n",
    "\n",
    "Whereas the $\\theta$ vector is presented as an $(n + 1)$ x $1$ column vector:\n",
    "\n",
    "<p style='text-align: center;'> \n",
    "$\\theta = \\begin{bmatrix}\n",
    "-40 \\\\ 0.25\n",
    "\\end{bmatrix}$\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiplication of a single sample by $\\theta$ (Andrew Ng style)\n",
    "\n",
    "\"As is\" we could multiply $\\theta$ by $x^{1}$, i.e. because the number of columns of $\\theta$ (1) would match the number of rows of $x^{1}$ (also 1).  However, this would arrive at the incorrect result.  For instance:\n",
    "\n",
    "<p style='text-align: center;'> \n",
    "$\\begin{equation}\n",
    "    \\begin{bmatrix}\n",
    "    -40 \\\\ 0.25\n",
    "    \\end{bmatrix}\n",
    "    \\cdot\n",
    "   \\begin{bmatrix}\n",
    "   2104\n",
    "   \\end{bmatrix}\n",
    "    =\n",
    "    \\begin{bmatrix}\n",
    "    -84160 \\\\ 526\n",
    "    \\end{bmatrix}\n",
    "\\end{equation}$ \n",
    "</p>\n",
    "Which provides a different result to:\n",
    "\n",
    "<p style='text-align: center;'>\n",
    "$h_\\theta(x) = -40 + 0.25 \\cdot 2104 = -40 + 526 = 486$\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, we need to do the following:\n",
    "\n",
    "1. Add a <b>bias unit</b>, $x_0 = 0$, to every sample $x^{(i)}$.  This transforms:\n",
    "\n",
    "    a. the hypothesis from $h_\\theta(x) = \\theta_0 + \\theta_1x_1$ into $h_\\theta(x) = \\theta_0x_0 + \\theta_1x_1$; and\n",
    "    \n",
    "    b. the $x^{(i)}$ matrix from a $1$ x $1$ matrix to a $(n + 1)$ x $1$  matrix, i.e.\n",
    "\n",
    "<p style='text-align: center;'> \n",
    "$x^{1} = \\begin{bmatrix}\n",
    "2104\n",
    "\\end{bmatrix}$\n",
    "becomes\n",
    "$x^{1} = \\begin{bmatrix}\n",
    "1 \\\\ 2104\n",
    "\\end{bmatrix}$\n",
    "</p>\n",
    "\n",
    "    and\n",
    "   \n",
    "\n",
    "2. Transpose the $\\theta$ matrix to transform it from am $(n + 1)$ x $1$ matrix to a $1$ x $(n + 1)$ matrix, i.e.\n",
    "\n",
    "<p style='text-align: center;'> \n",
    "$\\theta = \\begin{bmatrix}\n",
    "-40\\\\ 0.25\n",
    "\\end{bmatrix}$\n",
    "becomes\n",
    "$\\theta^{T} = \\begin{bmatrix}\n",
    "-40 & 0.25\n",
    "\\end{bmatrix}$\n",
    "</p>\n",
    "\n",
    "3.  Therefore we can rewrite the equation $\\theta^{T}x^{(i)}$:\n",
    "\n",
    "<p style='text-align: center;'> \n",
    "$\\begin{equation}\n",
    "    \\begin{bmatrix}\n",
    "    -40 & 0.25\n",
    "    \\end{bmatrix}\n",
    "    \\cdot\n",
    "   \\begin{bmatrix}\n",
    "   1 \\\\ 2104\n",
    "   \\end{bmatrix}\n",
    "    =\n",
    "    \\begin{bmatrix}\n",
    "    486\n",
    "    \\end{bmatrix}\n",
    "\\end{equation}$ \n",
    "</p>\n",
    "\n",
    "Which provides the same result as $h_\\theta(x) = -40 + 0.25 \\cdot 2104 = -40 + 526 = 486$!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiplication of sample by $\\theta$ (numpy matrices)\n",
    "\n",
    "Unlike the above, using numpy matrices has the effect of ogranising features / $\\theta$ values as columns and samples as rows.  For instance, using numpy matrices the above $x^{1}$ and $\\theta$ values are presented as follows, where $x^{1}$ is $1$ x $1$ dimensional and $\\theta$ is $1$ x $(n + 1)$ dimensional:\n",
    "\n",
    "<p style='text-align: center;'> \n",
    "$x^{1} = \\begin{bmatrix}\n",
    "2104\n",
    "\\end{bmatrix}$\n",
    "</p>\n",
    "\n",
    "<p style='text-align: center;'> \n",
    "$\\theta = \\begin{bmatrix}\n",
    "-40 & 0.25\n",
    "\\end{bmatrix}$\n",
    "</p>\n",
    "\n",
    "Although the number of columns of $x^{1}$ (1) already match the number of rows of $\\theta$ (also 1), mulitplying $x^{1}$ by $\\theta$ produces an incorrect result:\n",
    "\n",
    "<p style='text-align: center;'> \n",
    "$\\begin{equation}\n",
    "    \\begin{bmatrix}\n",
    "    2104\n",
    "    \\end{bmatrix}\n",
    "    \\cdot\n",
    "   \\begin{bmatrix}\n",
    "   -40 & 0.25\n",
    "   \\end{bmatrix}\n",
    "    =\n",
    "    \\begin{bmatrix}\n",
    "    -84160 & 526\n",
    "    \\end{bmatrix}\n",
    "\\end{equation}$ \n",
    "</p>\n",
    "\n",
    "So to fix the issue we do the following:\n",
    "\n",
    "1. Add a <b>bias unit</b>, $x_0 = 0$, to every sample $x^{(i)}$.  This transforms the $x^{(i)}$ matrix from a $1 x 1$ matrix to a $1$ x $(n + 1)$ matrix, i.e.\n",
    "\n",
    "<p style='text-align: center;'> \n",
    "$x^{1} = \\begin{bmatrix}\n",
    "2104\n",
    "\\end{bmatrix}$\n",
    "becomes\n",
    "$x^{1} = \\begin{bmatrix}\n",
    "1 & 2104\n",
    "\\end{bmatrix}$\n",
    "</p>\n",
    "\n",
    "    and\n",
    "   \n",
    "\n",
    "2. Transpose the $\\theta$ matrix to transform it from a $1$ x $(n + 1)$ matrix to an $(n + 1)$ x $1$ matrix, i.e.\n",
    "\n",
    "<p style='text-align: center;'> \n",
    "$\\theta = \\begin{bmatrix}\n",
    "-40 & 0.25\n",
    "\\end{bmatrix}$\n",
    "becomes\n",
    "$\\theta^{T} = \\begin{bmatrix}\n",
    "-40 \\\\ 0.25\n",
    "\\end{bmatrix}$\n",
    "</p>\n",
    "\n",
    "3.  Therefore, multiplying $x^{1}$ by $\\theta^{T}$:\n",
    "\n",
    "<p style='text-align: center;'> \n",
    "$\\begin{equation}\n",
    "    \\begin{bmatrix}\n",
    "    1 & 2104\n",
    "    \\end{bmatrix}\n",
    "    \\cdot\n",
    "    \\begin{bmatrix}\n",
    "    -40 \\\\ 0.25\n",
    "    \\end{bmatrix}\n",
    "    =\n",
    "    \\begin{bmatrix}\n",
    "    486\n",
    "    \\end{bmatrix}\n",
    "\\end{equation}$ \n",
    "</p>\n",
    "\n",
    "4. Note multiplying $\\theta^{T}$ by $x^{1}$ returns an incorrect result despite the dimensionality matching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.3. All Samples\n",
    "\n",
    "#### How the data and $\\theta$ values are arranged\n",
    "\n",
    "In Andrew Ng's course, an entire dataset of input variables $x$ is represented in the upper case, i.e. $X$.  This represents a matrix of $m$ x $n$ dimensions, which for the above dataset $X$ is $4$ x $1$:\n",
    "\n",
    "<p style='text-align: center;'> \n",
    "$X = \\begin{bmatrix}\n",
    "2104 \\\\1416 \\\\ 1534 \\\\852\n",
    "\\end{bmatrix}$\n",
    "</p>\n",
    "\n",
    "Whereas the $\\theta$ vector is presented as an $(n + 1)$ x $1$ column vector, which is $2$ x $1$ for the above scenario:\n",
    "\n",
    "<p style='text-align: center;'> \n",
    "$\\theta = \\begin{bmatrix}\n",
    "-40 \\\\ 0.25\n",
    "\\end{bmatrix}$\n",
    "</p>\n",
    "\n",
    "\"As is\" we cannot multiply $X$ x $\\theta$ or $\\theta$ x $X$ because in either scenario the columns of matrix A don't match the rows of matrix B. \n",
    "\n",
    "As above, the solution is to add a <b>bias unit</b>, $x_0 = 0$, to every sample in $X$.  This transforms the $X$ matrix from a $4$ x $1$ matrix to a $4$ x $2$ matrix, i.e.\n",
    "\n",
    "<p style='text-align: center;'> \n",
    "$X = \\begin{bmatrix}\n",
    "2104 \\\\1416 \\\\ 1534 \\\\852\n",
    "\\end{bmatrix}$\n",
    "becomes\n",
    "$X = \\begin{bmatrix}\n",
    "1 & 2104\\\\ 1 & 1416\\\\ 1 & 1534\\\\ 1 & 852\n",
    "\\end{bmatrix}$\n",
    "</p>\n",
    "\n",
    "Therefore, the number of columns of $X$ (i.e. 2) now matches the number of rows of $\\theta$ (i.e. also 2), meaning we can do the multiplication $X$ x $\\theta$ like so:\n",
    "\n",
    "<p style='text-align: center;'> \n",
    "$\\begin{equation}\n",
    "    \\begin{bmatrix}\n",
    "    1 & 2104\\\\ 1 & 1416\\\\ 1 & 1534\\\\ 1 & 852\n",
    "    \\end{bmatrix}\n",
    "    \\cdot\n",
    "   \\begin{bmatrix}\n",
    "   -40 \\\\ 0.25\n",
    "   \\end{bmatrix}\n",
    "    =\n",
    "    \\begin{bmatrix}\n",
    "    486 \\\\ 314 \\\\ 343.5 \\\\ 173\n",
    "    \\end{bmatrix}\n",
    "\\end{equation}$ \n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3. Multivariate Linear Regression\n",
    "\n",
    "### 5.3.1. The hypothesis\n",
    "\n",
    "$h_\\theta(x) = \\theta_0 + \\theta_1x_1$ + $\\theta_2x_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2. The Data & Theta Values\n",
    "$\\theta_0$ = -40\n",
    "\n",
    "$\\theta_1$ = 0.25\n",
    "\n",
    "$\\theta_2$ = 0.25\n",
    "\n",
    "<img src=\"../Images\\multiVariateData.png\" width=40%>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2. Single Sample\n",
    "\n",
    "Same as above for univariate linear regression, i.e. add the bias unit $x_0$ to each sample $x^{(i)}$ and transpose $\\theta$ to allow us to multiply $\\theta^{T}$ by $x^{1}$ as follows:\n",
    "\n",
    "<p style='text-align: center;'> \n",
    "$\\begin{equation}\n",
    "    \\begin{bmatrix}\n",
    "    -40 & 0.25 & 0.25\n",
    "    \\end{bmatrix}\n",
    "    \\cdot\n",
    "   \\begin{bmatrix}\n",
    "   1 \\\\ 2104 \\\\ 5\n",
    "   \\end{bmatrix}\n",
    "    =\n",
    "    \\begin{bmatrix}\n",
    "    487.5\n",
    "    \\end{bmatrix}\n",
    "\\end{equation}$ \n",
    "</p>\n",
    "\n",
    "Which provides the same result as $h_\\theta(x) = -40 + 0.25 \\cdot 2104 + 0.25 \\cdot 5 = -40 + 526 + 1.25 = 487.25$!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2. All Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as above for univariate linear regression, i.e. add the bias unit $x_0$ to each sample $x^{(i)}$ to allow us to multiply $X$ by $\\theta$ as follows:\n",
    "\n",
    "<p style='text-align: center;'> \n",
    "$\\begin{equation}\n",
    "    \\begin{bmatrix}\n",
    "    1 & 2104 & 5\\\\ 1 & 1416 & 3\\\\ 1 & 1534 & 3\\\\ 1 & 852 & 2\n",
    "    \\end{bmatrix}\n",
    "    \\cdot\n",
    "   \\begin{bmatrix}\n",
    "   -40 \\\\ 0.25 \\\\ 0.25\n",
    "   \\end{bmatrix}\n",
    "    =\n",
    "    \\begin{bmatrix}\n",
    "    487.5 \\\\ 314.75 \\\\ 344.25 \\\\ 173.5\n",
    "    \\end{bmatrix}\n",
    "\\end{equation}$ \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Useful Resources\n",
    "\n",
    "- https://machinelearningmastery.com/matrix-operations-for-machine-learning/\n",
    "- https://machinelearningmastery.com/introduction-matrices-machine-learning/\n",
    "- https://towardsdatascience.com/linear-algebra-cheat-sheet-for-deep-learning-cd67aba4526c\n",
    "- https://betterexplained.com/articles/linear-algebra-guide/\n",
    "- https://blog.stata.com/2011/03/03/understanding-matrices-intuitively-part-1/\n",
    "- https://towardsdatascience.com/linear-algebra-for-deep-learning-f21d7e7d7f23\n",
    "- https://medium.com/from-the-scratch/deep-learning-deep-guide-for-all-your-matrix-dimensions-and-calculations-415012de1568\n",
    "- https://www.mathsisfun.com/algebra/matrix-introduction.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
