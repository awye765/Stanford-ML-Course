{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4: Multi-Class Classification - Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook covers a Python-based solution for part 1 of the third programming exercise of the machine learning class on Coursera.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Setting the Scene\n",
    "\n",
    "For this exercise we'll use logistic regression to recognize images of hand-written digits (0 to 9).  We'll be extending the implementation of logistic regression we wrote in week 3, and apply it to one-vs-all classification.  \n",
    "\n",
    "<b>Note:</b> the dataset's $y$ values map the digit \"$0$\" to label \"$10$\" to avoid confusions with indexing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': b'MATLAB 5.0 MAT-file, Platform: GLNXA64, Created on: Sun Oct 16 13:09:09 2011',\n",
       " '__version__': '1.0',\n",
       " '__globals__': [],\n",
       " 'X': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " 'y': array([[10],\n",
       "        [10],\n",
       "        [10],\n",
       "        ...,\n",
       "        [ 9],\n",
       "        [ 9],\n",
       "        [ 9]], dtype=uint8)}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = loadmat('ex3data1.mat')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Do some initial analysis!\n",
    "\n",
    "As always, let's prioritise checking the dimensionality of our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 400), (5000, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['X'].shape, data['y'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us the $X$ matrix of features is $5000$ rows x $400$ columns and that the $y$ vector of labels is $5000$ rows x $1$ column.\n",
    "\n",
    "This is because:\n",
    "\n",
    "* $X$ is a matrix comprising $5000$ example images (the \"<b>Sample Matrix</b>\").\n",
    "\n",
    "\n",
    "* Each of those $5000$ images is itself represented by a $400$ feature dimensional vector, i.e. each row in $X$ represents a single image $x^i$ (each an \"<b>Image Vector</b>\").\n",
    "\n",
    "\n",
    "* Each feature in each Image Vector $x^i$, i.e. from $x_0$, $x_1$, ... $x_{400}$, is a numerical value corresponding to the grayscale intensities of each pixel in each original 20 x 20 pixel image, ranging from between 0 (white) to 1 (black).\n",
    "\n",
    "\n",
    "* The class labels are in the vector $y$ as a numeric class representing the digit actually displayed in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 - Plot the Data\n",
    "\n",
    "For instance, these images look like the below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAisAAACCCAYAAACHIognAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzsnXd0FcXbgJ/dzc1NBQJJ6AQEJIQOAtI+paj0KgpSBaSIdKkCCogISBVFKdL9Sa8KiAiI9N4RYiQQCCGBBNLL3f3+uGfHJAIGksDduM85niMpl3mZmXfeedtImqZhYmJiYmJiYuKoyM97ACYmJiYmJiYmj8M0VkxMTExMTEwcGtNYMTExMTExMXFoTGPFxMTExMTExKExjRUTExMTExMTh8Y0VkxMTExMTEwcGtNYMTExMTExMXFoTGPFxMTExMTExKExjRUTExMTExMTh8Y0VkxMTExMTEwcGqcn+WFvb2/Nz88vWwYSHBxMRESElC0fnkGyUz6AkydPRmia5pNtf0EGMGXMPDldRnMvPhtMGTNPTpfR3It/80TGip+fHwcOHMjQz8qyjCRJJCQkEB0dDYCqquTKlQur1Ur6N4nq1KnzJEPJFvz8/Dh8+HCGf16WZWRZFrLYbLbH/ryzs3NwpgaYBTxORkmSkOW0zjZZlrHZbKiqmqHPdxQZDx48+I+vS5KEoihCRk3Tnkg2HRcXF4eQ8dChQ+LPqWVLTk4WX5dlGUVRUFUVm832j333MGrVqpUtY34S0suXESTpb51+8uRJPvnkE2bOnEnp0qX/McdWq9Xh5vBR6HrUZrPh5uaW4c93FBkfthfTo69T+Htf6v//OBxlL2ZURlmWUVX1kTontQ5WVdWwexEQciiKQkpKyiPnMqPr1AwDmZiYmJiYmDg0T+RZySiKohAbG8vevXvZsGEDGzZsACA2Npbu3bszb948nJycMnTLc0R06zcqKoobN27g7e0NQIECBZ74lu4oSJKEqqpEREQACI/DX3/9RYUKFfD09AT+/abjqEiSRFJSEoGBgVy9ehWAvHnzUr58eby8vAwtF9hvMUFBQdy4cYPTp0+TkpICQJEiRfD19aVQoUK8+OKLYn0aVd5Hoa/fH3/8EYABAwZw79493NzcDC+roigsXLiQH3/8kR9++IG8efMC/+7JNQL67TsqKoorV64QERFB6dKleeGFF8T3jTx/qT0l8fHx3Lp1i/z58+Ph4fGP+dNlvXnzJmA/T4yKJEniLAkMDKRq1apYLJZMzWWWGiv6pJw7d44pU6awZcsWcuXKxYgRIwDw9fXl008/Zffu3TRp0sRwmy21m/nYsWOMHTuWixcv8n//938ALFq06KEhLkdHV/QbNmxgzpw54uspKSkEBQVRv359Zs2aBUChQoUMZ5BJksT9+/cZOXIk27dv586dOwC4urpSoUIFJk+eTL169Qwplz7mffv2MWjQIC5fvoyLi0uaNRgfH0+JEiUYM2YM77zzDgBWq9Vw++9RKIpCTEwMs2fP5ssvvwTAx8eHFStWUKBAAcPtx/Romkbt2rWZMWMGJ0+epFGjRoB9/o0sm6IonD59GoBBgwYREhJCmTJlSEhI4K233gKgd+/ez3OImUKSJGw2G1euXAFgypQpHD9+nJo1a/Lpp59SsGBB4O+Lw40bN9ixYwffffcdAGPGjHk+A39CUofVdVkkSWLy5MkAHD16lG3btmX6Uphlxoosy1y+fBmAjh078ueff/Laa68xduxYatSoAdg9KytWrGDt2rU0adIkq/7qZ4IkScTFxQEwc+ZMFixYQFhYGJIkiXhlWFgYJUqUELdao6B7HbZt2ybyWSwWC87Ozjg7O7N7925CQ0MBKFy48PMc6lOhKAoLFixg5cqVvP7663Tr1g2A0NBQ5syZQ79+/diyZQslS5YEjHNj1ecNYOrUqdy8eZMPP/yQNm3aCBkiIyPZvn07v/zyC7179yY42B4eHj16NM7OzoYz0NKjaRq3bt1i4sSJrFq1ity5cwPw4YcfUrt2bcPfzMGeu1CxYkVsNhu7du3ilVdeARA5HkZEkiRiYmJ49913AahUqRI//PADVquV/v37M2HCBADeeOMNSpQoYZg9qaN73gcNGsRPP/0E2C8Nuuekdu3avPfee4B9DV+/fp2OHTty9uxZkXO2ZMkShz9LZFnmxIkTAJw6dYpOnTrh4uICQEhICMA/Lk9PS5Z6Vv744w8AvL296dKlC/369SN37txioHfv3iU8PJzixYtn5V/7TJBlmUuXLgF2C7lQoUJ8+eWX7Nmzh+3btwMwf/58xo8fj7u7u6E2l6qqWK1WJkyYIA7syMhI9uzZw40bN/Dy8qJ06dKAMcMHqqrSrFkzNE3jgw8+ECEtRVGwWCwMHz6ckJAQIaNR5k6SJOLj4wH7fP3www80btw4zfglSaJZs2YEBwfz3XffMWPGDMA+j6NHj8ZqtRrSYHFysquuoKAgevTowe+//07+/PlZs2YNAPXq1RMJxUZcs6mRJImbN2+SmJhoeFl0ZFkmJCQEd3d3AKZNm0aBAgWIjo7G3d1drElVVZEkyVBeJN2jMn78eDZt2iSSops0aULNmjVp0KAB/v7+7Ny5E4Ddu3cTFBTEhQsXaNWqFV27dgWgdOnSvP32289Njn9DURSCg4Pp0KEDAA0aNKBLly7i+/oezSqy7NP0AwGgUaNGuLq6IssyKSkp4gagxyRfffXVrPprnxmSJPHzzz8DkJycjKqqdOrUie7duzN//nwAPvvsM86fP8+8efMoXry44Q6BEiVK8NFHHwH2+ezZsyeBgYFommY4WVKjqiply5bF399frEmdxMREihUrRrFixQwno6qqwpPw66+/4urqSnJy8j+UuiRJFCtWjJEjR5IrVy4ARowYQZs2bahSpYrhDnQnJyeOHTsGwKhRo9i/fz8NGjSgQYMGbNmyBYBNmzZRuHBhmjZtSvHixf9R5WYkJEkiKioqw9VcRkDTNNzc3ERI9sSJEzRt2pTcuXPToEEDMb9Wq5XQ0FAuXLhAw4YNDXORUFWVXbt20bp1a+ElKliwIJqmcffuXSZOnMjixYsBuH//Pn5+fixdupQ33ngDDw8P8RmpUw8cCVmWCQ0NpWfPniK3ZsqUKeLykzpErVcGZ/rvzPQnmJiYmJiYmJhkI1nqp9E9KO7u7uI2LkmSiMFt2LABV1dXWrZsaahbrCzL3Lp1ix07dgDQokULAgICCA8Pp2TJkgwaNAiAMmXK0L9/fzZt2sSQIUOe55CfCpvNhsViAeD69etcvHgRJycnh7XunxQ9f0Ffp6GhoSxduhQvLy/y5MljuFurpmnCY6BXvTxMBk3TSElJwcXFhc6dOwMwd+5ctmzZQsWKFZ/pmDOLLMsEBwczffp0AH7//XcCAgIoUKAAISEhLF26FICkpCRUVWXt2rVs2bIFLy8vAEPpndToazdfvnyG9hLpqKpKsWLFaN68OQBDhgyhePHilCtXjlatWok8x3379rFp0yaGDRv2PIf7xMiyTJ06dShXrpwIL1++fJmxY8fy+++/ExkZSYUKFQB4++23ad68OaVLl0bTNJGH5uhs2bKFvXv3smnTJsCe/pHaa+3r6wvAzZs3SUlJyfQ5kqXGiq4oUytMRVHYvXs3AOvXr6dXr16GOxgkSeLHH38kMDAQgK+++opKlSqRkpKSZhKaNm1K586d+e233+jVq1cad55RSN3gzkhzlBHSr89t27Zx5swZevXqlSZ3Q2/cZAQetucehaqq4tBu27YtISEhaJpmGGNUlmUiIiIYMmQI27ZtA+zJex4eHvz000/ExcVRt25dwO5y379/PzExMSQkJDzPYWcZejjT2dkZwDCH2qPQNI1x48YB9oqRDh06sGrVKvLmzSuqEvfu3cvChQupVauWwyebpkaWZcqVK8fcuXO5e/cuAAcOHODYsWPkyZOHfv36iQttoUKFRJ6LEdCLTVatWkX9+vVFWocsy6IliSRJBAQEAHaDMyvmLkuMlfSdT/VkKEmSePDgAbNnzwbghRdeYMCAAaIrqhGQZZmEhAT279/P66+/DkDZsmXTjF8/KGRZxtXVlTt37hhGvkdx9+5doqKiDJXYlhFSK4UHDx5QuHBh9uzZQ0BAgPA69OvXT8SXcwJ6zDi1PLIsExgYSFJSElar9TmOLmMoisKVK1fo1KkTly5dIk+ePID9wD537hw+Pj4sXrxYJIhPmzaN8PBwOnfujLe3t2GMz3/DyBVA6VFVVfSMWblyJW3atKFly5bkzp0bHx979/UlS5ZQvXp1Q+lT3eP55ptvsnHjRlFOrygKZcqUYcGCBVStWjVNp1ojrU9FUVizZg1Hjhyhd+/e/PXXX8Dfnnlvb29y587NgwcPALvXNyvWbaaMFf0fOyYmhuvXr4sFFRISQqFChfD09GThwoWcOXMGgDVr1oi+B0Y5BCVJ4tKlS2zevJmNGzcC9rLeR20em80mmqgZQb5HERcXR2JiYo5wOacmdejk3XffFdUz+/fv54svvgDsN4Hly5cbsmQS0l4eJEnizp07RERE4OfnJ6qHNm3aJA52R96LuhwRERGMGzeOy5cvU61aNXFbvXHjBnnz5qVZs2Zcu3ZN3MgPHz5M27ZtGTRokKEbUKYnp8iRHnd3d3Lnzs358+dxd3dnyZIlABQtWjTN8xFGQVVV/Pz8GD9+PN27dwfsrTuqVatGuXLl0nhvjTanmqZhsVioXr06J0+eFOXnmqbh7u6Om5sbvr6+nDx5ErB7jrJiDz6VsaK7je/cucP8+fNZvXo1qqqKsEdMTAxgP7gjIiKEVbV//35cXV0pVaoUrq6uhnE/BwUFER0dLSov0qPLd+vWLXbv3k3//v1RFMWQB51ObGwsSUlJomwwJ6Fvmjx58oibXfny5YU7s3PnzrRr145ffvnFkCFLsO81gHnz5hEUFMTt27cpXbq0KCe8ffs2VatWFcbbk4STniW6sRIcHMy+fftE/ph+a5MkidjYWFavXi2qngAmT55Mt27d8PLyMtSt9VHktD0I9rnVz4revXsTGxvLyJEj+fbbbwkLCwOM2ddJR1VVKlWqJDqcx8fHs3btWh48eMCMGTMoUqQIYJxWCTo2m4233nqLVq1aPfT79+7dY82aNWzduhWAunXr4uHhkWndkrOuzSYmJiYmJiY5jif2rEiSRGJiImDvgvnLL7/w/vvvU6lSJdHs7cKFC4wcOZL4+HjeffddcTtasWIFU6ZMoXTp0rRu3VpkeOsJY46IXtX0qKRLWZbFLe/999/Hw8ODZs2aGf42d/PmTaKjo4W3LCeSOlYsSRLlypUDYPny5bRp04YtW7bQvXt3Q918JEkiMjKSAQMGAHDx4kWcnZ2RJInDhw+L242TkxM//fQT/fr1o1mzZrRs2RJwvL2Y2uPj4eFBTEwM4eHhYk4SEhIoVKgQ9erV48MPPxRJffo7JEbfh2Cf02vXrmVJRYUjIUmSCL1euXKFrVu34u3tzb59+9i1axcAVatWfZ5DzDSp+zpVqFCB+vXrs2rVKrp168bcuXMBKFeunKF0DNj1h145mp7cuXPTuHFj0YDSy8srSxrEPZWxored37FjB71792bs2LFIkkR4eDgAM2bMIDk5mS+//JJWrVoJhTN48GDu3LlDbGws7u7uhsiHkCSJfPnyoapqmiQhSZJQFIW4uDimTJkC2MNFq1evxs3NzXCLLz2p8xgcLTSQVaROPE19CAQHBxMXFyeSOI1GSkoKsbGxgH3ukpOTRaa+Hvby9fUlKCiIixcvUrlyZYc9BPV9VKlSJXbt2sXAgQPZsWMHnTp1AqB79+4UKlSIIkWK4OrqmqbzaU7ijz/+eGjDP6OzYsUKwF6+W7p0aZKTk3nppZeIjo5+ziPLPJqmYbVaxQXAarXSuXNnihUrRr9+/cSF4vvvvyd//vyGWrOPaySpF9bo52WZMmVwcnLKdEXQExsrmqbh6uoKQOXKlQkPD+fWrVucPHlSPFiYN29eNm3aJLpj6hQtWpSiRYuKA0JXRI6+AV1dXXFxcRFvHVSpUoWUlBRu3rzJuHHjOHfuHGC/kfv7+xuqxO5RyLJsCGPyadAP5sjISCIjI8mdOzeKonDt2jUAxo4di9VqpVGjRoZSIIDoxTF+/HjAXhVTuHBhihQpQrNmzURpr6urK/Hx8bi5uYn9rP++IyLLMi+88AJ9+vThzJkz4uZdq1Yt6tSpg5OTk+Hm6knRNI2IiIg03kBHna+Mol8ITp48KZKmL168aMgu5+nRNA1PT0+R2zFt2jQaNWqEm5sbuXPn5vjx44C9C/NXX32Fm5ub4dewoiiEhYUxZswYYayktwOelqfyzeiljn369GHUqFEcOHCAa9eu0bFjRwAmTpz40HJBI3obNE2jfPnyvPHGG8ISPn78OPfu3ePHH3+kfPnyrF+/HgA/P78cYaiA3RAtUKAA4eHh+Pj4OOzN+2nQN9G1a9dEQz+LxcLZs2cB+/qeNWuWaLRmJHQvkf6mSP369cmTJw8WiwUXF5c0FQh680ajkJKSwhtvvMHPP//M7du3AahWrRqKohheyT8OTdOoVKkSL774Ii+99FKarxsZTdMYO3YsYD9L+vbtK8KVH3/88XMeXdagaRqDBw8G7I02d+7cya1bt9K07wgNDSUpKUm8k2Rk9HBtsWLFxFt6WcVTeVb0g6t58+bUrVuXpKQkFEUR1TI56fl5VVVxd3fn22+/FTHGTZs24eTkxKRJk2jbtq14ZTInKExdhooVKzJ27Fh27drFxIkTxZsyOUFG3aCsWLEia9as4fDhw2zdupUGDRoA0Lp1a8qWLfs8h5gpNE0TMeIiRYqIQy29IW3Ew06WZfz9/UVuSkpKiiHleBJUVaVBgwYcPnw4R4SYdTRNEx1sp0+fznfffUeePHlYt24d1atXB4yvb1RVFbpz/vz5XL16ldDQUC5fviyaFTZp0gRPT0/DywqIquC+ffuKkvOs6lmVM/38JiYmJiYmJjmGpwoDpbaS9IS91F/PKZa/jqZpeHt7M2nSJMAe5tK9Szml4kBHn0NJkujRowc9e/bMcTLqSJJEgQIFaN26Na1bt07zPVVVDX1jz6l7Eewy5US5HoX+npXeaNLI6zI1qRs0du3ala5du4rvGbVh2sPQZXB2dqZ8+fKUL1+e1157Lc33c9K8pqSkUKtWLWrXrg1k3RmZ6XqinHiIPYz/ipw6OWnzPI7/2ryaGJOcuh9zslGdnv+SrsmO9So9yQdKkhQOBGfpCP7GT9M0n2z67AyRzfKBKeMzwZQx0+R0+cCU8Zlgyphpcrp8kEEZn8hYMTExMTExMTF51pgJtiYmJiYmJiYOjWmsmJiYmJiYmDg0prFiYmJiYmJi4tA8UTWQt7e35ufnly0DCQ4OJiIi4rm2Sc1O+QBOnjwZ8byTpUwZM09Ol9Hci88GU8bMk9NlNPfi3zyRseLn58ehQ4eeflSPoVatWtnyuU+Cn58fBw8ezLbPd3Fxyc6M6gzxX5Hx8OHD2fb5zs7OhpdRkiRkWX5oD4SXX345s8PLNH5+fhw5cuSpf1+X71H9ciwWi0PM4ZPq09Tvdf1beajVanUIGTOibyRJSvOkR0YfUXUUfZNdOlXvVfI8cZQzI/PvNps8Ev0NmpzaVM3EGOiPUqY+uG02G5GRkTg7O+Pi4pJmrRoZ/cBLSkoiJiYGT09PLBZLjpBLkiTWrVvH1q1bAVi8eLGhH3BMbXjFxMQQHx8v/uzh4QGQ5iVtk/82Zs6KiYmJiYmJiUOTaWNFt/gz+t9/Af3p9j///JM///yTsLAwQ8huhDGaPBmyLHP//n0CAwOJjo4WXpZt27ZRsmRJBg0alGNurvq+0zSNOXPmUKJECYKCgnLEupZlmd9++40BAwawceNGNm7cyNixY0lISDCkfJIk8eDBAzZv3szmzZtp2rQpJUqUoGjRopQqVYoePXrQo0cPrl27lsYDY3T08KTFYsHZ2RlnZ2ecnJwMOYcPQ5fPyckpzX9ZMYeZCgPpBkhKSopQFGBvK6x/T1GUNAM1+psrOoqi/CO8o09UdHQ0q1atYtq0aQAMHDiQoUOHPq+hZghdyeuv9aZW/DnlMHtSUuc9gD10YhSlou+5+/fvM3nyZA4ePIinpye+vr4AHDp0CFVVyZcv3/McZpYiyzJ37twB4Ntvv8Xd3V2EE4yMoiiEhoYyePBgkpOTcXV1BeC7776je/fuBAQE/ONFbUdGlmX++usv+vfvz4EDBwAICAhgzJgxFC9enL179/LDDz8A9vd05s+fj6urq+HPDV2fhIaG8tVXX/Hnn38C0KBBA7p164aTk5OhZdTPxPDwcBYvXkxsbCxgz3mpVasWAQEBmZLvqYyV1HHhXbt2sWzZMnx9fQkMDAQgMDAQWZapUaMGFSpUoEKFCoD9ufqAgADDT4qqqly/fh1PT0+8vb1FvD8+Pp5Dhw7x6aefcuDAAUqWLAnYnwB35LcvZFlmw4YNzJ07l/feew+AihUrkjdvXvLly4ebm5uQUVVVUlJSDD1/6dHXs37A6wZKfHw89+7dY82aNQBcuXKFcePGPbdxPgm6geXh4cHkyZNZsWIF/fv3F7I6OTnRokULRowYgbOzs+HnU780ffXVVwDcunWLTp06kT9/fsPKpq/HpKQkhg0bxtWrV3FycuKdd94BYMKECeTKlctQhopOVFQUiqIwevRoAN5//308PT2RJIm33nqLmJgYALZv387169cpW7asQ+vQx6HvOVVVOXLkCG+99Rbu7u7kypULgB9//JGCBQvSrFkzwHh5Y/o6jYiIYNmyZXzzzTd4eXlRpkwZAM6fP8+BAwdYuHChMGiehqcyVvTb96FDh+jatSuapuHp6YmnpycAbm5uSJLE0aNH2b59u1hkuXLlYsmSJTRq1Agw3qToB/aff/5J+/bt8fT0pHXr1litVgBOnjzJ1q1bxUb79NNPAXjxxRcd3jtRvnx5Tp48yahRowBo27Ytt27dwtnZGU9PT/LkyQNAuXLlaNeuXY646eibLDo6mtjYWMLCwgD75rp69Sp//PEH4eHhFClSBLBXyehr3NHRZbPZbBw8eJAVK1aQL18+8fWoqCgKFSqEl5cX0dHRuLi4AH/vbaOhKAp79uxh3rx5APj4+DB48GCcnZ0NechJkiR0xrx589i5cydWq5U8efLw/vvvA/YX740om6qqVKpUiQ0bNgidmvoQs1gswnsUExPDtWvX8Pf3f27jzQx6dAHg+PHj9OzZk+bNmzNixAjx9ddff528efOmiU4YBUVRuH79OgBvv/02J06cYObMmbzzzjvCixsVFUVoaKioPnxankoz6ZuoSJEiDB06lLJly/LSSy/h5eWV5ucSEhIIDQ0VN9Ovv/6aPXv20KBBA8O403UkSRLZ6p988gmenp7UrVuX5cuXk5CQAECJEiWYOHEiV69eZe/evdSrV+95DjnDqKrKiy++SHBwMFeuXAEQVnF0dDRXr15lz549APTs2ZOKFStStWpVkpOTn9uYnwb9SXr9wL59+zYLFizg119/TVMxUqxYMYoUKUKnTp2oUaOGMNSMUlWiKAqJiYkArF69mmHDhiHLMvPmzaNy5coAdO3aleDgYGJiYggLC6NEiRLPc8iZQpZlEhISWLt2LZGRkQD079+fcuXKOfwl4VFIksS9e/cA+N///oeqqthsNqZPn065cuUADLf/0pPaML5z5w6BgYEcOXKE0NBQfvnlF8AeQihbtqzhzgv4O03i3LlzAPTq1Yt69eoxa9YsPDw8hE6NjIxElmXDySjLMnfv3uXdd98FIDY2lrNnz+Lv748kSSQlJQHw/fffM336dH777TcKFCjw1Hsy52QumZiYmJiYmORInsqzorseixYtmiaGn/7WmStXLgoWLMiNGzcAmD9/viHdlmC/rf74448AbNy4kaVLl9KmTRs+/vhjccNxcXHBarUSFxfH7du3RcjACLc7VVXx8vKiZs2agH0uJUnCy8uL4sWLExAQANhDXYULFzaETOmRZZm4uDjWrl0LwIIFC3jjjTdYtGgRXl5euLu7A/akvqdpUOUIKIpCZGSkCOetWrWKChUqMHv2bGrVqiX24rVr16hZsyYWi4WCBQuKW64RZEyPJEns3buXVatWUbZsWcB+i5Vl2bD6BuDzzz8H7LlSTk5ODB48mJYtWxoyR+VhSJLEqlWrAJg5cyZBQUFomkZKSoqYtzJlynDp0iWys4NqdiFJElFRUcLzUKBAAT7//HPc3NxITExk2bJlAHh7e1O0aNF/bfLnaDg5ObFmzRouXrwIwJEjRyhRogSqqpKcnCzSIObNm8d7771H3rx5n30YSEfTtH9VBpIkie53NpuNSpUqZTp29ayRZZkbN24wYcIE8edFixaxe/duJkyYQMGCBQG7fCkpKTg7O1O8eHHDHejpx5t6jtatWwdAjRo1KFCggHDxGQlVVZk7d64wsPv27Uu/fv0oWLBgmqRhoykNHUVRiIqK4sMPP2T58uWAPbn7iy++EHlTV69eBexxZE3TcHFxMWSsXEc3QOfOnYvNZqNfv36APXxg9ENd726rhxOKFCliON35b3z77bcAnDt3Dnd3d3Lnzk3Tpk157bXXAJg1axY9evRg27ZtVK1a1VA6VQ/lxcXFATBu3Djy5MlDYmIiR48eZceOHQB06tQJX19fw8mmF5ToNoAsy1y9epUbN26wc+dOZs2aBcCwYcOYMGFCmsrKpyFbs+lkWSY8PFzEH93c3ChfvjyyLBtGkUiSREJCAlOmTBH5HAUKFODOnTv89ttveHh4iBtQ6ionIy28xyHLMpGRkeLw27Rpk2HmLj2yLPPaa68Jr8nly5d5/fXXmT9/vvAoGRVJkoiNjeXjjz9m6dKltGzZEoCFCxfi7e2NzWbDycmJqKgo4G9D9MGDB8TGxlKoUKE0XzcSmzZtYv/+/ZQtW5auXbsCxt5/ennrgwcPAET7hzFjxrB48WKRRFytWjXD7kWwr7WZM2cCdg9gwYIF6dixIwULFhQJtu7u7rRp04aNGzdStWrV5zncpyI5OVnM42effcb27du5ceMGR48exdvbG4B4wlsoAAAgAElEQVTBgwcbrhOxJEkkJydTtGhR8ubNC9grSBVFITk5mbi4ONzc3ABo1qwZFosl0zlW2Was6DXle/bsISgoCLBXmJQqVcpQkwKwcuVKFi1axFtvvQXAiBEjiIyMpGXLlty6dUtYlkatpHgU+qH+9ddf065dO8CeVG1kBfnSSy8JwyQpKYndu3fzwQcfsGHDBooXLw5gyNCBoigsWrSIxYsXU7t2baZPnw4gDBVZlomPj+enn34C7ErU398fq9VKaGioyNw3yhrWx3nnzh3mzZuHzWZjzJgxohzUaDomPalDITqapnHhwgVmzJgBwOzZs/H29jasrJqm8dJLLwF2jy3Y917q3k4uLi5omsa1a9cM1ecI7GuwePHi4jKrJw9funSJpKQk6tatC0DBggUNp3NUVcXV1ZWJEydSpUoVwJ60rygKqqpSrFgx4cGuXr16lpwZ2WqsxMXFsWPHDlGZULduXTw9PQ0TQpAkibCwMMaMGUP37t2FWytXrlycOnUKTdMoVKiQKEHLaciyTGBgIGvWrBHeMaMqRlVVuXPnDt7e3uKgk2WZRo0aMXfuXK5du2bIihi9sun69eusWLECq9XK6NGjKV26NIDwqMTHxzN16lRWr14NwIABA+jWrRuyLKcpaTYCiqIQHR0NwNChQzl79iw9e/akRYsWhsovehxWq/WhhqPVak0Tkh06dKhh9Gl6UlfA6KFXvWJPn7+zZ88iSRI1atTAycnJUIe6pmk4OzuLvjh6/5g2bdoQHR0tLr9GRc9rbN68OQAXL17kk08+YdWqVXz00Ud069YNyLpGsMbRUCYmJiYmJib/SbLVsxIYGMiePXtEQ5+GDRsayjIGu/XYpUsXhgwZIqpFbDYbYWFhKIpCmzZtRFM4I4dH0qMnXS5btoyhQ4eKMIFRZVRVlXHjxjFq1CjRQ0aSJE6dOkVoaKjIxjcSqRNjV69ezfnz5xk7dqxougj222tYWBhTp05l5cqVokPx5MmTcXZ2RlVVfHx8DOOR0HuqTJ48GYD169dTrVo1xowZY9gGcE+K7o3QEzeNhiRJ2Gw27t27Jxpogr0Kz8fHh+joaHbv3g3ApEmTKFGiBO3atTOkVzf1fnJ2diY0NJTz58/TpEkTEQZy9D33OPQkfbB7/c6ePUv37t1p3759luuUbDFW9NbXkyZN4sGDBwwaNAiAQoUKGWrBaZqGr68vn3/+eZqW5GfOnGH48OGUK1fOkDk4GUGWZdavX8/169cZO3as4Q8BRVFwd3dn9erVfPjhhwDs3r2b8ePH89577+Hn52dIGfU1GRcXhyRJ1K5dGycnJ4KDgwF718y5c+eK7pljx44FEIZK6s9wdPRDbvXq1SxYsAAALy8vPvvsM1HRlRNQVZUCBQqIZoSBgYG4u7uLsIk+b87Ozs9zmE+EbmAlJCSwePFifv/9d8LDw0UTP0mSsFqtlChRgrCwME6cOAHYZZw5c6bhzo7U6LLHxMQwZcoUJEmiffv24pJrlP33MFI3f/voo49ITk5mypQpeHh4ZLk+zVJjRZ8USZLYuXMnu3btom7dunTv3l183UgLTlEUVq5cybFjx6hataq4yUydOpUGDRowf/58LBaLoWT6N/T8m1u3bon4o9VqNeRBnhpZlunatStjxowRj6flzp2bL7/8kpo1axoqcS81uqLT4/y9e/fGxcWFu3fvAvb3OsqUKcPKlStp0aKFyE0x2prVy3fXrFnD2LFjRWXB6NGjqVmzpuHk+TdsNptoq3/ixAmWL1/O3bt3KVu2LK1atQLsvWSM0sVW319RUVEsWbKEc+fO4ebmliZXymazcfz4cfLlyyfyILp3786rr75q6ANdl/Hy5cv8/PPPNG7cmDfeeEN838iyKYrC999/D9grun7//Xd8fX2zZV1mqbGiT0p4eDjTpk3Dy8uLUaNGiRuC0RSKLMv8+uuvrFixAvj7IG/Xrh1Tp05NczvNCeg3V4ApU6bQrVs3KlasaHhDBewKoUqVKqxcuVI8m1CoUCHDhw70Q6Bbt25ERkbyzTffYLFYaNKkCQAVKlSgW7duopGfUdernuw+fvx47t69y0cffQTYXzTPaRcGsK/Xjh07AtC+fXvatWvHjRs38PHxoVq1aoD9kUqjyK2P09vbm08++YSZM2fy119/iQtgYmIiRYoUoUuXLjRq1Eg8C2GxWESFkBHRq/DA3vjOxcWF0aNH54jHQxVF4c8//2TSpEkAjB07NlvPiywzVlJ7TdauXcupU6do27Yt1atXN0w8PD0pKSlMmzaNESNGcO/ePfLnzw/YDzmr1WoYRZFRZFnm999/B+ydavW8gJyCJEn4+vqKA95msxnaUEm9n4oWLcqUKVMYNWoUkiSJ/Cqr1Wr4Tq5glzVPnjwcPHgQWZZFiXJONFR0Uoe1ateuLXKU9Lk0otyKotCsWTPq169PUlJSmnVpsVjw9PRM03PE6OtWkiTRZ2XNmjX06tULf39/wzae1FEUhbCwMFq1akWtWrUAe2VednrhzWogExMTExMTE4cmS8NAukUVFBREXFwcERER3L17lwIFCmTlX/PM0DSNvHnzki9fvn983chW8cOQJInExEThTfnss8/IkyePYWLiGcWIt9GMoPdT8fHxAdK+Z2T02yn83bNCr0rT5zGnzmd6cto+dHd3x8PD4x9f11+Xzilomia8nJMmTeLtt9829PMWOpqmoSgK7777Lp07dwbsc5qdc5elxoqe0zF8+HC6deuGqqoi49mo5ETD5GHoDX6+/PJLAIoXL57jFGROJ6cYJo8ip8v3X+K/olf1Tq9gr5YxeuhZR1VV8uXLx/Dhw0W4Mrvlkp5kwUiSFA4EZ9NY/DRN88mmz84Q2SwfmDI+E0wZM01Olw9MGZ8JpoyZJqfLBxmU8YmMFRMTExMTExOTZ42ZYGtiYmJiYmLi0JjGiomJiYmJiYlD80QJtt7e3pqfn1+2DCQ4OJiIiIjn2kbU29tbK1as2BP/Xurup48Lq506dSrieccfs3MOAU6ePGnK+Az4L+xFcw4zhynjs8Hci5kjo3P4RMaKn58fhw8fztDP6u2xM5r1/fLLLz/JULKFYsWKiVbsqdE7KKZ+sl2vnpEkicWLFwNQqlQpXn311UeWU7q5uWVnklKGeNwc6vLA02frOzs7O4SMhw4dyrbPt1qtOVpGvcnT88TPz4+DBw8+8e/pXbT1dfyo5+ldXFwcYg4zqk+fBqPtxdT6JzWP00WOshcfdm5kBXXq1MmWz30SHjWH+ltVqdHn6knOjozOYbaFgVJSUnjw4EGOKNOSZTnNGxaapomJOn36NIMHD2bw4MGMHz+e+/fvG/KdGf1BqvDwcMLDw0lMTPzX30n9b5KTkCQJWZaxWCw4OzuL//TSfBPHxGKxEBcXR1xcHLNnz6Zhw4aEhITk2HWak9C7LO/evZvq1atTsWJFKlasyLJly0hKSjKkTs3prFu3joCAACpXrkzlypWZOHEiZ8+eFT2fshpzF5uYmJiYmJg4NFlv/mC3kgMDA+nSpQsrV67kxRdfBIz7zkN696T+4N+2bdsYMmQIFSpUAGDQoEG4u7sbstmRJEl88803DBs2DIAtW7bQvHnzNO+TpP/50NBQvLy8AGM9V58efW71G7jNZiM8PJxz585x+/ZtsW6rVatG2bJln9s4s4LUsqYP+4Ex96guw7lz5xg+fDgAhw8fxmKxEBQUxNPkoTkC/+ZNMKKeSY++5xISEpg8eTKff/45/v7+1K9fH7B3fX355ZcpW7bsI3WRybNFlmWuXbvGoEGDaNmypTgD1q5dy7Rp0+jRowd9+/alTJkyAFnWsTdbjBVN08ifPz+XL1/m/Pnz+Pv7A8ZUhA9DlmW2bdtGz549adq0KV988QVAmlbnRnJbKopCVFQUO3bsEM/PV6lS5ZG5N7IsExISwttvv82GDRsAyJ8/v+Fan8uyLLqiRkVFiafOjx07xvnz5wkPD6d69eriBWP99XCjIkmSeOX2xIkT7Nmzh1u3bqFpGrlz5wZgzJgxz3OIT4wesjt9+jT9+/fn9OnTAOTNm5eUlBQCAwPFwefo6MZjegNSb0Gv/1n/vpOTU44wWAB27NjBjBkzaNWqFXPmzBFPnPzxxx85ykh52COqkiShKIphzgz9UdFRo0bRr18/cVEdMmQIR48eZdCgQWzcuJFNmzYB9kteVpz92WKs6Giaxvnz58UBaPQ3EfRbwMWLFxk0aBCVK1dm1qxZwkjRFYoRFp0+D4qiEB4ezsCBA/H29mbhwoUAuLi4PNL4kCSJwMBAjh07li2xyWfF/fv3WbRoEcuXLycmJobw8HAA6taty4ABA2jTpo14BRb+9qgZEVmWOXDgAD169ADg3r17JCQkkJCQgIeHB97e3gCUL1/eEOs3dQLtvn376NmzJ/fu3aNXr16A3dj+7LPP2LJlC2+//bZ4h8YRDerU/95xcXFERUURFRUlkjYvXbrEvn37uH37NpqmiWKE77//HqvValidKssyly5dAqBPnz4MHz6cMWPG4OrqSnR0NGB/Tdyo3ur0yLJMQkICy5cvZ8uWLRw/fhyw51otX76c+vXrO+T6TI9+uenfvz+SJAlj0tfXlxYtWlCzZk0GDx5M69atAbshGhAQkGnZsuWkkSSJoKAgVFUlMjJSKHgjH2ypn/r+5JNPiI+PZ968eXh7e4vJelQ2uyOiG16xsbGMGDGCrVu3sn37dlxcXIDHK3VVVTl9+jSvvPKKePfCKMpETyQG+OCDD1izZo14sPKHH34AoGHDhri5uYl5NYICSY++DnXPQ0hICH379hVGSf369SlSpAgVK1YkX758FClSBAAvLy++/vrr5zbujKB7xABWrFjBuHHjAOjSpYvwcgJs376dkydPEhISQkBAAOB4c5laXxw+fJg5c+Zw6tQp7t+/T2RkpPgZJycnsWdPnDgBwF9//UVAQIDhDWgADw8PevbsiYuLCzabTdzWP/vsM/LmzWtYGeHvN/Nu3rzJmDFj2L17NwMHDhT65eLFi+TNm/d5DvGJSf1Qqo4+Rz4+PsyePZvatWsD8NVXXzFnzhwURcnUOZFt1oOmaaiqapjDOyP873//A2Dr1q2MHj0af3//NCXNepmkEbwruuI7cuQIa9euZeLEidSpUydDytxms7Fnzx4aNmxoSGNl3759AJw9e5aCBQsSExPDtGnTaNq0qfg5Iz/iKEkSMTExAOzevZu6deuSK1cu1q9fT+HChQH7xcHJyUnczI30irHNZmPFihUAjBs3jri4ONq2bcuUKVPEXrRYLPj6+nL9+nX++usvypcv/zyH/Fj0Q2vZsmVs2bKF4sWLkzdvXooXLw6Av78//v7+lCxZko8++khcmqKiohxezzwKRVE4f/48U6dOBaBHjx4UKVJE6FD9gPf19TXEmnwUsizzxx9/ANCyZUvatm3L2bNnOXr0KKtWrQLgm2++oUKFCoaWMzU2mw0fHx8WLFgAwJtvvkm/fv2oUKFCpoxOsxrIxMTExMTExKExblzmGSJJEuHh4eIWULt2bQYOHIiiKNy/f1/EXf38/PDx8RG5OY5665EkScSER4wYQZs2bejfv3+Gf19VVfbs2cPrr7/+j2RAR0fTNH799VcAmjRpwvr16xk2bBidOnV6qGvTiNhsNvr06QPA/v372b9/P76+viJvA/6WUQ+JGQVnZ2d27tzJ6NGjAbusfn5+TJ8+HQ8PD3E7TUpKIi4uDlVVM9Qz6HmhaZoIeYwcOZKOHTuK6kKLxQJArly5kCSJ+Ph4tmzZwk8//QT8e7WQIyNJElu3bhVz0717dxRFSZN0quPk5JQmwdhojBo1CrA3W5w0aRKurq78+uuvIqn9l19+oVChQlSuXDnHeFcAKleuDNhzA+/du5fp9WoaKxlAkiRu374tNlaHDh3Ily8fe/fuZerUqaK7n5+fH23atGH48OEOXcqbOkxw+fJlFi9ejNVqzbCLTjfEjLixNE0TSZgLFizA1dWVQYMGoSiKIeVJj8ViYeXKlfz8888ATJw4kWLFij1VZ0lHQ1EUIiIimDFjhjCyChQowNdff42Xl1ea+Tt06BDHjh3jhRdeoGzZsg49t/q+K1GiBCVLlvzHWG02G4qicPfuXU6dOiXyG4oWLerQcj0KvSrtwoULNG/eHIDChQtjs9lEjtW9e/cACAoK4syZM3To0AFXV1dDrt+QkBDAfj6EhYVx/vx59u/fL3KPbt26xYABA57nELMFPecKsqaBaLYbK0ZcXOmRJImjR4+SkJAAQEBAAJcvX+bNN98kPj5eWJC3b99m2rRpvPbaa9SsWdOhZdeNKUVROHz4sJDh33BycuLq1avEx8dn5/CyBT0BWk8mPXToEI0bN8bd3d2QSv9RREdHC8/ZwoULCQ4OpkWLFrz88ssiF8CR1+bDkCSJ5ORkvvnmGw4fPkyuXLkAe4Jt9erVSU5ORlEUIfesWbO4ceMGXbt2pUSJEoZI0FRV9bEVeMnJydy7d0+U9ab2lBkJWZaJiorixIkTtG3bFvh7b+rJ+7pn8OrVqyQlJeHn50ejRo0MMY/p6d69O2DPSerQoQPlypWjRIkSnD17FoAJEyZQvHhxw+kgPfFbH7feu0nTNJKSkkQkokqVKiK/MzOYnpUMoKoqV65cwWq1AvaKCf3GOnv2bCpVqgTYm+L069ePyMhIhy7TVlVVuCDHjx/PzJkz8ff3p27duiJBMX2Wt+5VCg8PZ/369aiq6tDeo/SkrgLS3ZF+fn5899131KhRg+bNm4v5ddR5ywgpKSl07NhRlNPv3LmT9evXs2TJEpYtWyZ6xhhNRkVR+Pnnn5k1axaKoojmhdWrVyclJQVFUUhMTGTSpEmA3bWeK1cuRo0ahbOzs+EOgvSoqsrFixeFUQZ2L5rR5hHs++/u3btcuXKFRo0aia/LssyFCxdo06YN9+/fByBfvnzcunWL2NjY5zXcTKGqKv369QOgffv2KIrC8ePHee+99xg5ciRg99QbbR51fbp161aOHTsGgKurKxaLhRdffJGbN2+yfPlywJ4E7+Pj45ily/B3T5U8efLkiDdV3Nzc0pSDuri44ObmRpUqVUQHP1VVsVgsVKhQweEXnz4nvXv35vbt2/To0YOSJUsK5VGqVCnRLO3QoUPCq+Tp6Ska/b322mvPbfxPiiRJnD17FlmWqVGjBgBff/01Q4cOpWPHjnTo0EFkr7u4uDj8/D0KTdPw9PSkXbt2ADRv3pzg4GBGjhzJwIEDhWLJkyePIQ5w3Xi+cOECI0aMICkpifbt29O3b1/gbz1z/vx5xowZw2+//QbY1+nq1aspXLiwoSu74O/+Pps3byYmJkZ4BnOCXk3dXVhVVbZs2cKdO3dEC4WIiAiKFClC7dq1DbFeH4auSwoUKMD58+fp0KED77zzjjBWHPli+zD09di/f39WrVolLnn58uUjJiaG+Ph4NE3D3d0dgHLlyhEdHY2Hh0em0gfMaiATExMTExMThybbmsLp9fIFCxYUNwAjxhvBLs+bb77JN998A8DcuXPp06cPXbp04f333xfeiK+++opBgwZRsGBBh7eUdevWw8ODadOm0aVLF5YuXcqaNWsACA0N5f/+7/9o3749vXr14oUXXgDsfQ/ef/99XF1dKV26tGFurTabjQMHDlCrVi0xN7ly5WLu3LlIksT333/PkCFDAKhatarDz9+jSL/XnJ2dKVasGEWLFuXGjRuGvY0fPXqUwMBASpYsyZgxY4SX8/Tp06xYsYIlS5aQmJgowlwfffQR5cqVyzGt2mVZpmTJkjg7O4sQmF4tZDR0j3vx4sVF3kbJkiWRJIn33nuP0qVLC69DSEgI48ePx9vb27CeFX3PnT9/niZNmtCsWTMmT54swuhGlEtVVTZv3kyFChVYvHgxAGXLluXgwYM0b96cpKQk4XF56623KFOmDH379qVDhw5pIhFPQrYZK2fOnMHd3Z3SpUtnx1/xTFFVFX9/fz7++GPA/n7K2bNnefDgAatXrxZvIPTu3ZuxY8em6bDp6OjjrFSpEl988QV3794F7G2/fXx88PDwSCNLbGwsV65cMUSoKzWKouDm5saJEydEZ0U9ZDJo0CCWLl0q3s0xKpqmsXnzZry8vKhZsyZgb243efJkfvjhBxo3biwOOCPMnSRJIlfqzJkzWCwWZFlm+vTpotLgyJEjhIWFUapUKTp06CDCQ/rbQEaQ89/QNE28c+Tu7k61atUA0pT6GglVVcmfPz+vvfYac+bMAexJmL6+vty/f5+9e/eKasWJEyfy5ptvPs/hZgpFUfjzzz8BaNOmDa1atWLy5MlpyuyNiCzL+Pv7ExoayuXLlwG4ceMGCxYswN3dnRkzZlCrVi3AnuT/v//9j5EjR1KtWjXxdYcwVgBiYmK4f/8+3377rXjLwqjvWOgdFfUM9fLly7NkyRJq167Nyy+/LPoilCpVSniVjNYDIXWrZPjbO5b6KQGwJ3DGxcVlSSnas0SSJBo2bEi3bt1EF1f9VekFCxaQP39+Q7+orCgKq1atYujQoQAiXpyYmMjdu3dp1KgRH3/8seg4bIRDTtM0cTtr374927ZtIygoiEuXLon1FxAQQO/evRkyZAgWiyXNOjU6uixJSUl89913rFu3DldXV2bNmgXY39Px8fEx1OUI/u4t07FjR7p16wbYPSt6V+Xy5csze/ZsANq1a2fYBGlZlrl69SrNmjUDoEWLFkyePFk8KWBUNE3DYrHw9ddf06lTJ7p27QrYjY9y5coxY8YM3nnnHbFHZ82axbhx47h9+zYlS5Z86r2ZLcaKqqo0bNiQ+vXrM2DAAMNXWaRPgKpXrx6vvPLKP3pXGKXV/uPIiFLIly8fjRs3NpQCsdlslCxZkvnz5/POO+8A9nb7zs7OLF26lA8++EBUSBlxneoVFnFxcdSqVUu4mGvVqkXVqlWpXr063t7ehlOS+nhr1KjBtm3bROty3bVerlw5/Pz80rxQnNOwWCwEBASQnJxMp06daNmyJYDQq0YkJSWFV155RfQDOnnyJGAPzdaqVUuECozaDE5RFG7dukW7du1EaFIP/RhtDz4MVVUJCAhg586dXLx4EbB7cWvUqIGXl5fwBurky5cPb2/vTPV6yjZjpWzZsmzevFnc5HISj+uHkFPRF5i7uzs//PDDY19ldlRUVaVixYriZjphwgQePHjApEmT6NOnj2F7kIBd+ffp04eOHTvi4uIiDGYXFxesVispKSmGVJL6XOhuZ/1BQh2bzWZIuTKCLrvFYmHv3r3ExcVhtVpFTyRZlg17mIN9zeppAv7+/oBdZpvNZmjPmCzLhIWF8dZbb9G8eXM++eQTwD6PRtOZj0K/lBcqVEhUp4F9Pz5MxqxoSGksX76JiYmJiYnJf45sbQrn5uaWYyxJEzuSJP0j6dZI2Gw2Ub2VuiGV0VvRg/3m5u3tDaT1Dhnt/Z+Hkd6t/F9C0zTxPlCdOnVELkBO0K26VywnecdsNhvDhw+nQoUKjB8/XiS154T5Ss+z9Gxmq7GSEyfHxJhhktTk1HWZEwwuk39is9no27cvTZs2pVixYmL9mnPtmGiaxtixYylYsKBhk4MdEelJFrwkSeFAcDaNxU/TNJ9s+uwMkc3ygSnjM8GUMdPkdPnAlPGZYMqYaXK6fJBBGZ/IWDExMTExMTExedaYCbYmJiYmJiYmDo1prJiYmJiYmJg4NKaxYmJiYmJiYuLQPFE1kLe3t+bn55ctAwkODiYiIuK5tn7NKvn0hlzp84FOnjwZ8byTpbJzDsGU8VnxX9iLxYoVy7bPP3XqlGHm8FH65N8w2jrVNI34+HhcXV0z3AXcaDI+KY6yFx1Bnz6RseLn58fBgwcz9LOSJJGSkiLekgH7YvTy8nroWxb643LPEz8/Pw4fPpzpz4mNjSUhIYE8efIAf7cGd3Z2zs6M6gzh5+fHgQMHMvzzTk5OyLIselz8Wxmeq6ur4WR8UhxFxozsRUmSkGX5H9159U6hDzsAHWEvFitWLMNzKEmSkFPn33qyuLm5OcQcPkzf6LpT74+j689cuXJhtVozXAprJH0jSRIhISHcvXuXihUrZvjzHX0vpn6qJSUlBScnJx48eEBiYiL58uUDeOw7a46wF/9NPn38uo5RVfWJOiu7uLhkaA7NMJCJiYmJiYmJQ5OlTeGcnOwfl5CQwLp16zhw4ABhYWHs27cPsHfS/P7772nevLkhOxb+W+dISZJISEigQYMG5MuXjw0bNgD2fxejlYjrFvP58+cJCgqiYcOGgP2tGaPKot/A06O/9WQ0uR6HfstJTk7m5s2b/PHHH8TExIgOt3ny5KF06dKGbVqlz6OiKNy/f5/79+8THh4u5vCll14yZMdbSZJITk5m4cKFrFu3DoBDhw4hyzLt27enU6dONGjQAHj8jdxoaJrGwYMHuX37NlWqVDHk+ZAe/Tz47rvvAPDw8KBEiRIMGzaMixcvMnXqVAA++OADQ+/BGzduAHD06FE0TaN06dIEBASIx1Sz6v2qLDNWNE0TL2guX76cdevWYbPZcHV1FYoT4KOPPuLVV1/Fzc3NUIeDzWbj+PHjAJQtW/ahLef1w/3UqVMsXboUDw8PwFjP1ac+BHbt2sWAAQMIDQ3l888/B6Bfv36GkUeX5e7duxw6dIgjR44QHh7+D4Olfv36NGzYULhljbQuH4aiKFy/fh2AqVOn8vvvv3PlyhVSUlLEa7a5c+embdu2TJgwAWdnZ0PJLEmSCI0sXLiQHTt2EBERwe3bt4Ucc+bMoW3btv94Md3R0Q+4zZs3s3//fsC+56xWKydPnqRPnz5MnjwZgHfeeceQh1xqdIMrJCSEefPmMX36dEPN1+OQZZnr168zf/58AAYOHMiuXbuYOXMmy5cv56uvvgLg3XffNdx5qF8Af/zxR8aMGQPA9evXsXHrc5gAABKDSURBVNlseHp60qxZMzp37gxAvXr1gMzr1SwxVvQY619//QXY3yjp2rUr//d//4e/vz9bt24FYMaMGVy/fp0//viDatWqGcZ6VhSF8+fP06FDBwC+/fZb3njjDXFo64dfXFwcc+fOpVChQtSsWfO5jfdpSa3Y586dy+LFi1m4cCGBgYF8++23ALz33nvIsmwIJanPy7Zt2xg0aBCqqj70nZw1a9ZQo0YNVq5cCdifMzeS4kiNLMvcunWLjh07AnDs2DH8/f3p0KEDpUqV4vTp0wD88ssvLF26lP79+1O0aFHDyCvLMoGBgXTq1AmAixcv4uHhgaIo5M6dm3v37gH2A/7Bgwe8++67z3O4T4ymabi6uvLqq6+iJxh/+umn5MqVC5vNxuzZsxk9ejQA1apVo0yZMobYi49CPwO++eYboqOjKV++vKHlSY2mady5c4cePXoA0LNnTzRNw2KxsHXrViGnEb3VOocPH+bKlSsAjB07liZNmrBv3z5mz57Nxo0bAViyZAnNmjUDMmewZImxok9Anz59AOjVq1ca17s+KdOnT8dqteLn52eoydE0jcOHDwtPSb169dJ4F3TPUUhICPv27aN+/fr4+fkZxhjTURSFI0eOAPDFF1+wfPly6tevj8ViEYfArFmzeP/993F1dXV4paKvsTp16tCoUSMKFCjA66+/LubLycmJuLg41q1bx/bt28WNdcaMGc9tzJnFyclJeBoAFi1aRMOGDSlQoAAHDhzgt99+A+yhr8qVKxvOMJNlmaCgIIKCggDw9fXl448/JiAgAB8fH5YtWwbAzJkzmTVrFp07d8ZisRhGRk3TcHJyYujQoSKsnjrcExsbS1hYGAD79u0jICDA4ffh49B1ZFhYGNWrV8fNzS2N59Mo85YeWZa5e/cus2bNYvbs2YD9Ei9JEhcvXmTTpk20aNFC/KwR5dQ0jZ49e/LLL78AMG3aNF5//XWGDRtG48aNhZE2cOBAfH19qV69uvi9pyFLw0CpPQ36ny0Wi3BnqqpKwYIFyZ07t2EmR5ZlLly4wKRJk3jzzTcBcHV1faghEhwcTGRkJHXq1MHFxcUw4RKwyxkbGytubaNHj+bVV18lOTmZ/PnzC1n2798vjFJHR19jpUuXZuXKlSiKkiYsmZiYSHh4OIsXL0ZVVS5evPg8h5sl2Gw2ateuzZYtWwB48cUXuX37NuPGjWPZsmVERkYCULVqVebNm4e7u7uhDjtVVSldurR4ybZx48Z07twZV1dXgoOD01Qt1KpVK00I2ihomobVahV/1i9+e/fuZf78+RQtWhSA1q1bG0rHpEeSJKKiogDYsWMHs2bNQpZl4uLihAfU1dVVzLWRkCSJ6OhoTp06JWS8fv06R44c4bPPPqNw4cIifGJEdN2aP39+YUzXrFmTF154AVVVKVeuHMuXLwegUqVKLFq0iKpVq2YqzyrnZGiZmJiYmJiY5EiytBpIR7e6ZFkmLCxM5AKoqkrLli0NlcVus9mYOnUqmqYxbNgwIK0bS5IkYmJiALsbLCAggLfffttQISD95va///2PxMREwJ70paoqiqJw5swZEVaoVauWiJ8bhf9v79yDqqq+OP45515ALipJwkXJAXxkkpZTidhglpnPxkeNYg2UEt4ss/GRWZHaKKmjwUyl+MApy0dmWaaOpkmkmJOVND4KyTJNU0HQUNDg3nvO748zZ4v+qp+KP2Xj/vzDCHfkLPY+e6+91netbRgGDRo0AKxoih1Gnz17Np9++innzp2ja9euZGVlAVY6TCb7auL3+2nbtq1IIRQVFfHwww9z7NgxHA6HCD3PmDGD2NhY6aqgDMMgJiaG559/HoDc3Fx+/vlnXC4XM2bMEH1LQkNDeeGFF3A6ndKOpR3xKi8v588//yQtLQ2fzycim+Hh4VKN3cVomkZBQQEAJSUlhISEUFBQQHp6OkVFRYC1Dr388stS7RlgjV1ERAQDBw4Ueg2751h1dTXJyclifGUTgdtomkZ1dTVlZWWA9c7ZUTDTNPF6veJzV+MdvKrOip1rtL8GBASQl5fHvn37AIiNjSU5OVmazcAOU27cuJG0tDSaN28ufmbrcXRdF1VQW7duJS0tjUaNGkk1+TRNo7Kyki+//JInn3wSQDSf0nWdffv24XK5AOjZsycgXy7Z5/OxcOFCdu7cyf79+wFrI7fFwo0aNaKyshKwwrVRUVHSCIlrcvE7CNZY2XZERUUB0KxZM/Ez2dA0TTgr69atY8iQITidTg4dOt9bqk+fPtxyyy3SjR9Y9pWVlZGRkQFYJaGnT5+mpKSEJk2aCKG/rutSrKP/hl3Vpes6mzdvJjc3l7KyMiGg3r59O1u2bKF79+5SzVXTNHG5XGRkZNC7d28AVq1axcqVKxk4cCAFBQU88sgjACxevJjWrVtLN5amadKwYUMSEhIAWL16Nbt37+b++++nuLiYiRMnAtCkSRNSU1NxOBzXX2ALXPAglZWV6LpOaWkpGzduFJ8ZO3Ysbdq0kWYB0XWdFStWUFVVRZcuXUQe1Z5UJ0+e5PDhwyLiEhgYSIcOHa7b814puq5z+PBhNm3axFtvvSW+5/f7+fjjj8nJyaFNmzaApXWQLU+u6zqFhYVkZGRQXl4u6v/tDsNg9bIYOHAgYJ1Yk5OTSU1NpXHjxtLMV7uPzNmzZ8VpJyQkhAULFvDZZ5+Rm5vLokWLAMt5mzlzphRC6YsxTVPY17x5c3bt2iXKr5OSkgBLJB0cHCzVBmfjcDjIz8/no48+AiAmJobIyEieeOIJ8vPzRYVTZmYmd955p3SbXE1spzowMJB3330Xp9PJ3LlzxTjm5eWxYMEC7rvvPun0R4ZhEBISInpUbdiwgY4dOzJnzhz279/PgAEDAJg6dSrz5s2Tbr6apomu6yIi/ddffzF8+HAWL17M3Llz+fzzzwHo168f7dq1u6DY5kqotbNiRxcOHTok+pB88MEHBAYGcuLECb755hshFjtw4AAVFRWEhIRIMyiNGjXC4XAwfvx42rdvDyD+6Lt376a4uFhsfjk5OVL3digvL+f48ePi+3PmzGHevHl4vV7hPcuIYRi0bNmSlJQUqqurueuuuwCrX07NcbJfpPz8fJYuXcqRI0eYNm2aSCHV5TG1HZUdO3aQmZlJXFwcYFXmPfjggzzwwAMUFhaKiMSKFSt4/PHHSUhIkGq+6rrO8ePHGTZsGAA//PCDcFR8Pp8QwTds2FDaTdzn89G3b1/y8vIAaNq0KZqmcfPNN5OSkiJasGdlZbFgwQLp+uTUxF5TXS4XFRUVjBgxgkGDBgknJjQ0lJKSEpGSlg1N04Toe9myZaxZs4bw8HDCwsLo0aMHANu2baO0tFTKClLDMAgPt671mTZtGn379mXAgAFUVFSItebFF18kNDS01oeiWjkruq5z8uRJZs2axbp16wgJCQEsXUBwcDB79uy5ICUyZ84cTp06RXZ2thTlWn6/n6SkJLxeL4sWLeLgwYOA1RW0Z8+euN1uFi1aJCIrgwcPlmrhtzEMA7fbTZ8+fUhJSQGse0jatGlDdnY2kyZNYtSoUdf5KWtHUFAQ06ZNQ9M04Vz+Ux48Pj6eRx99lMTERO6++27Rs6Quj6umaRQXF/PMM8/QvXt3JkyYAFjOdnV1NZqm0a5dO5YvXw7A008/TV5eHvHx8dfzsS8LO0eemZnJd999B1il2mPGjKFDhw4XaFbsdKWsBAYG0rZtW+D8vPP5fDRr1oxJkyYBMHnyZP744w9atWol3SYHll0RERGAtd5UVFTQqlUrXC6X0M5t2rRJpKNlpLq6WqTzBg0aRKdOnfD7/WiaJg5Bl3ppY11E0zQxVl988QWnTp2iQYMGeL1eEaSwx7i2zoqcM0ChUCgUCsUNwxVFVmwv99y5c6L50tChQ/F4PAC899577N27F7AawtgiqlmzZvHhhx/y9ttvS+MpBwQEkJqaKhrcwPkT3uuvv85NN93E2LFjAaQUZIIVQXK73Sxbtkw0hWvatCkdO3bkl19+4ciRI0KzIjN2RMUeo38aK6fTSUhICD6fT/Qlqevouk5ubi4xMTFMnz5dnNrsU5yNrdNp3rw5e/fule7UWlVVxeHDh0WlQc+ePXnuueeIiIigoqJCdM2sqqqSqhncxdi3YtfETj/blXknTpzg22+/pWXLltfjEa8K9jxNTExk6dKlFBQUUFRUJIoyPvnkE2bNmiXl/WoOh4PCwkIKCwsBGDJkCIGBgfh8vgv2iotvDJcJTdNYv349AOPHj6dv375MnjyZtWvXCv1j+/btSUpKqnXW4bKdlZq/cPny5WRmZjJmzBhatGghhF+///47mqYxceJExo0bJ7pNnjlzhv79+4uyShkwTfO//sBOp5OcnBzefPNN5s6dS+PGjYHah7muJ4Zh4HK5RB7Vtnvr1q1ER0eLMZNtwajJvz17zcXjwIEDZGRkUFlZKVKbdR3TNGnbti2nTp3i6NGjonGYjd/vZ+/evcyfPx+wrhgYPny4lCFou9kkQHJyMhEREULTYIekvV6vlM3E/H4/r776KsePH2f27NmAdXAwTZOqqiqWLFnCG2+8AVgpPjvELiOmaYoDhMfjYfv27axYsYL169cLR62mRkdG7KogsBo0OhwODMPA5/MJG1NTU3G73dLtH7Z+zE5L9urVi4ULF+J2u7n99tvFejt16lS6detGVFRUrdKVV+SsnDlzBoDs7GyCgoKIi4sjPz9faDo6d+6Mx+PhscceIyAgQORes7KyxGDJuOnZAq+ioiJmzpxJnz59LhCDyWhTTS7uQnzu3Dmys7N56qmnCA0NFZ+pTzgcDjRNo7S0lJycHMC6BK+qqgqPx8OgQYOksNkwDNq3b4+u6/Tu3Zt77rkHgLCwMI4ePUpZWRn79u2jvLwcgB49ejBu3DjxPspCYGAgsbGx4t9btmwhKiqKXbt2kZWVJVp6y9aZ18Z2mpctW8aPP/4IWBoqr9fLr7/+yvfffy8cspdeeonExEQp5uc/YT97fHw8X331FWvWrCEvL09ojpKSkmpd8nq9ME0Th8MhWiKsWrUKp9PJb7/9RmZmpnA0Z8+eTUBAgHTz1S6xtyN9nTt3FoUauq7TqlUrAA4ePMhPP/1EVFRUraIrVxTisE/ZbrebPXv2kJWVRb9+/Vi9ejUA9957L2FhYfj9/gs8qavVHOZ6YPciARg9ejRBQUGkp6fjcrmktenfsNMKhw4dIj4+XjhqdvhdVmqeuA3DYM+ePWzYsIHt27eL6ovo6GgmTJjA4MGDpSonDAoKYsqUKaSmpop3Udd1EWJ2uVyMHDkSgAkTJhAZGSnVwcFuQ//KK6+IdOX8+fOZN2+esNOuBpIVXdd57bXXaN26tUhpvfPOO6IgITY2VlRZpKSkSJ3qqokttvV4PIwcOVJs3H6/X1r7TNMkOjqatLQ0AKZPn87777/PsGHDSE1NpX///gBSRlXAWj/j4uLEfVwej4f169fTpUsXDMMgNzcXgISEBFH1dU3TQIZhCJXvypUrOXv2LC6Xi+Dg4AtSBX/Xi0PWSQfnL2sEq4lPcHCw1OWRl0J4eDgjRozgjjvukN5OW2c0ZcoUjh07BkBpaSk7d+7E6/XSokULRo8eDVg3S8fExADyzFn7Obt27crmzZtZt24dAPv376e0tJShQ4fSsWNHIiMjAStCIZOjYmMYBmFhYaJfzLZt29ixYwfFxcWMGjWKxMREQJ5xuxg7beDxeEhOTgbON04Da9zstLP9+fqCrdORfa2xsW/QTk9PB+DZZ58Vt4PXjKTI6KiAZZ+maaKPzNdff83atWtZsmQJp0+fFhWkaWlp4mBUG+RU9SgUCoVCobhhqJXStWHDhqKPyt+p1+sbdirEPp3K6hFfCn6/n4SEBBHSk91W0zRxOp306tWLbdu2AXDbbbfRrVs3OnXqRFxcHG63W3xeRnvtk05MTIyIEl1MzfC6rPj9flGdduutt15QqWdHGmSOONjPbgszLxZ5yzg3b1TsdQfO9xupT3tlzfcsMjISj8cjqoJrfubvClUul1o5KzfqS3Oj2F3f7NQ0je7du/PQQw8B51802xmrD/ZejUVBBuqDU/K/uBFsvBGo7+N4rezTLucXaJp2Ajj0Pz94ZUSbphn+f/q/L4n/s32gbLwmKBtrTX23D5SN1wRlY62p7/bBJdp4Wc6KQqFQKBQKxbVGCWwVCoVCoVDUaZSzolAoFAqFok6jnBWFQqFQKBR1GuWsKBQKhUKhqNMoZ0WhUCgUCkWdRjkrCoVCoVAo6jTKWVEoFAqFQlGnUc6KQqFQKBSKOo1yVhQKhUKhUNRp/gNfT9MR48qnpwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x144 with 40 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 2))\n",
    "counter = 1\n",
    "for digit in np.random.choice(range(5000), 40, replace = False):\n",
    "    plt.subplot(4, 10, counter)\n",
    "    sub = data['X'][digit].reshape((20, 20), order = 'F')\n",
    "    plt.imshow(sub, cmap = 'Greys')\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    counter +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 - Define the Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first task is to modify our logistic regression implementation to be completely vectorized (i.e. no \"for\" loops).  This is because vectorized code, in addition to being short and concise, is able to take advantage of linear algebra optimizations and is typically much faster than iterative code.  \n",
    "\n",
    "However if you look at our cost function implementation from exercise 2, it's already vectorized!  So we can re-use the same implementation here.  Note we're skipping straight to the final, regularized version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) Define the Sigmoid Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Define the Cost Function\n",
    "\n",
    "Recall that the <b>regularized</b> cost function is as follows:\n",
    "\n",
    "\\begin{align}\n",
    "J_{reg}(\\theta) = \\frac{1}{2m} \\bigg[-y^{(i)}log(h_\\theta(x^{(i)})) - (1 - y^{(i)})log(1 - h_\\theta(x^{(i)})) + \\lambda \\sum_{j=1}^{m} \\theta_j^2\\bigg]\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(theta, X, y, learningRate):\n",
    "    theta = np.matrix(theta)\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    first = np.multiply(-y, np.log(sigmoid(X * theta.T)))\n",
    "    second = np.multiply((1 - y), np.log(1 - sigmoid(X * theta.T)))\n",
    "    reg = (learningRate / 2 * len(X)) * np.sum(np.power(theta[:,1:theta.shape[1]], 2))\n",
    "    return np.sum(first - second) / (len(X)) + reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See Week 3 implementation for line by line explanation of the above code and how it maps to the mathematical function above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) Define the Gradient Function\n",
    "\n",
    "Next we need the function that computes the gradient.  Again, we already defined this in the previous exercise, only in this case we do have a \"for\" loop in the update step that we need to get rid of.  Here's the original code for reference:\n",
    "\n",
    "### (i) Original Code (with loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_with_loop(theta, X, y, learningRate):\n",
    "    theta = np.matrix(theta)\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    \n",
    "    parameters = int(theta.ravel().shape[1])\n",
    "    grad = np.zeros(parameters)\n",
    "    \n",
    "    error = sigmoid(X * theta.T) - y\n",
    "    \n",
    "    for i in range(parameters):\n",
    "        term = np.multiply(error, X[:,i])\n",
    "        \n",
    "        if (i == 0):\n",
    "            grad[i] = np.sum(term) / len(X)\n",
    "        else:\n",
    "            grad[i] = (np.sum(term) / len(X)) + ((learningRate / len(X)) * theta[:,i])\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (ii) New Code (without loop)\n",
    "\n",
    "In our new version we're going to pull out the \"for\" loop and compute the gradient for each parameter at once using linear algebra (except for the intercept parameter, which is not regularized so it's computed separately).  \n",
    "\n",
    "To follow the math behind the transformation, refer to the exercise 3 text.\n",
    "\n",
    "<b>Note:</b>\n",
    "\n",
    "* We're converting the data structures to NumPy matrices (which I've used for the most part throughout these exercises).  \n",
    "\n",
    "\n",
    "* This is done in an attempt to make the code look more similar to Octave than it would using arrays.  Why? Because matrices automatically follow matrix operation rules vs. element-wise operations, which is the default for arrays.  \n",
    "\n",
    "Recall the gradient descent function for <b>regularized</b> logistic regression is as follows:\n",
    "\n",
    "\\begin{align*} & \\text{repeat until convergence:} \\; \\lbrace \\newline \\; & \n",
    "\\theta_0 := \\theta_0 - \\alpha \\frac{1}{m} \\sum\\limits_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}) \\cdot x_0^{(i)} \\newline \\; & \n",
    "\\cdots  \\newline \\; & \n",
    "\\theta_j := \\theta_j(1 - \\alpha \\frac{\\lambda}{m}) - \\alpha \\frac{1}{m} \\sum\\limits_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}) \\cdot x_j^{(i)} & \\newline \n",
    "\\rbrace \\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(theta, X, y, learningRate):\n",
    "    theta = np.matrix(theta)\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    \n",
    "    parameters = int(theta.ravel().shape[1])\n",
    "    error = sigmoid(X * theta.T) - y\n",
    "    \n",
    "    # Applies gradient descent to update theta values from theta_1 - theta_n\n",
    "    grad = ((X.T * error) / len(X)).T + ((learningRate / len(X)) * theta)\n",
    "    \n",
    "    # Applies gradient descent to update theta_0, which is not regularised by convention.\n",
    "    grad[0, 0] = np.sum(np.multiply(error, X[:,0])) / len(X)\n",
    "    \n",
    "    return np.array(grad).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6 - Define the Classifier\n",
    "\n",
    "Now that we've defined our cost and gradient functions, it's time to build a classifier.  \n",
    "\n",
    "For this task we've got 10 possible classes:\n",
    "\n",
    "1. $h_\\theta^{(1)}(x) = P(y = 0 \\text{ | }x; \\theta)$.\n",
    "\n",
    "\n",
    "2. $h_\\theta^{(2)}(x) = P(y = 1 \\text{ | }x; \\theta)$.\n",
    "\n",
    "\n",
    "3. $h_\\theta^{(3)}(x) = P(y = 2 \\text{ | }x; \\theta)$.\n",
    "\n",
    "\n",
    "4. $h_\\theta^{(4)}(x) = P(y = 3 \\text{ | }x; \\theta)$.\n",
    "\n",
    "\n",
    "5. $h_\\theta^{(5)}(x) = P(y = 4 \\text{ | }x; \\theta)$.\n",
    "\n",
    "\n",
    "6. $h_\\theta^{(6)}(x) = P(y = 5 \\text{ | }x; \\theta)$.\n",
    "\n",
    "\n",
    "7. $h_\\theta^{(7)}(x) = P(y = 6 \\text{ | }x; \\theta)$.\n",
    "\n",
    "\n",
    "8. $h_\\theta^{(8)}(x) = P(y = 7 \\text{ | }x; \\theta)$.\n",
    "\n",
    "\n",
    "9. $h_\\theta^{(9)}(x) = P(y = 8 \\text{ | }x; \\theta)$.\n",
    "\n",
    "\n",
    "10. $h_\\theta^{(10)}(x) = P(y = 9 \\text{ | }x; \\theta)$.\n",
    "\n",
    "\n",
    "Since logistic regression is only able to distiguish between 2 classes at a time, we need a strategy to deal with the multi-class scenario.  \n",
    "\n",
    "In this exercise we're tasked with implementing:\n",
    "\n",
    "* A <b>one-vs-all classification</b> approach, where a label with $k$ different classes results in $k$ classifiers.\n",
    "\n",
    "\n",
    "* Each such classifier decides between <b>\"class i\"</b> and <b>\"not class i\"</b>, i.e. any class other than i.  \n",
    "\n",
    "We're going to wrap the classifier training up in one function that computes the final weights for each of the 10 classifiers and returns the weights as a $k$ x $(n + 1)$ array, where $n$ is the number of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def one_vs_all(X, y, num_labels, learning_rate):\n",
    "        \n",
    "    rows = X.shape[0]\n",
    "    \n",
    "    params = X.shape[1]\n",
    "    \n",
    "    # insert a column of ones at the beginning for the intercept term\n",
    "    X = np.insert(X, 0, values=np.ones(rows), axis=1)\n",
    "    \n",
    "    # k X (n + 1) array for the parameters of each of the k classifiers\n",
    "    all_theta = np.zeros((num_labels, params + 1))\n",
    "     \n",
    "    # labels are 1-indexed instead of 0-indexed\n",
    "    for i in range(1, num_labels + 1):\n",
    "        theta = np.zeros(params + 1)\n",
    "        y_i = np.array([1 if label == i else 0 for label in y])\n",
    "        y_i = np.reshape(y_i, (rows, 1))\n",
    "        \n",
    "        # minimize the objective function\n",
    "        fmin = minimize(fun=cost, x0=theta, args=(X, y_i, learning_rate), method='TNC', jac=gradient)\n",
    "        all_theta[i-1,:] = fmin.x\n",
    "    \n",
    "    return all_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intutition - Line by Line Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Line 5\n",
    "\n",
    "Defines new variable, `rows` equal to `X.shape[0]`, which is $5000$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Line 7\n",
    "\n",
    "Defines new variable, `params` equal to `X.shape[1]`, which is $400$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Line 10\n",
    "\n",
    "`X = np.insert(X, 0, values=np.ones(rows), axis=1)` inserts into `X` array at index `0` the values described by `values=np.ones(rows)`, which is a column of $0$s in the same dimension as the number of existing rows, i.e. 500.\n",
    "\n",
    "In other words, it adds a $5000$ row column vector to $X$ at index $0$.  This represents the bias unit $x_0$ for each feature vector $x^i$.  In doing so, this transforms the dimensions of X as follows:\n",
    "\n",
    "* $X$ was $5000$ rows x $400$ columns; and\n",
    "\n",
    "\n",
    "* Is now $5000$ rows x $401$ columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Line 13 \n",
    "\n",
    "Creates a matrix of zeros of the dimensions k x (n + 1).  Specifically:\n",
    "\n",
    "* $k$ = rows = `num_labels`, i.e. the number of classifiers / labels, in this case $10$ (one for each digit between $0$ - $9$).  \n",
    "\n",
    "\n",
    "* $(n + 1)$ = columns = `params + 1`, i.e. $400 + 1$ = $401$.\n",
    "\n",
    "This matrix `all_theta` will store the weights for each of the 10 classifiers. In formula, it is identified as $\\Theta$. In other words, each of the $10$ rows will contain $401$ weights corresponding to a particular classier's intepretation of each feature.\n",
    "\n",
    "For instance, the first row, $\\Theta^1$, will correspond to the weights of classifier 1's hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) Line 16\n",
    "\n",
    "`for i in rang(1, num_labels +1):` executes the immediately below code for each classifier from $k_1$ to $k_{10}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (f) Line 17\n",
    "\n",
    "Creates a matrix of $\\theta$ parameters.  This matrix is:\n",
    "\n",
    "* Of the dimensions $1$ row x $401$ columns (i.e. $n +1$ columns because of the bias unit $x_0$); and\n",
    "\n",
    "\n",
    "* Each paramater value is set equal to zero.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (g) Line 18 \n",
    "\n",
    "#### Recall that:\n",
    "\n",
    "* $y$ is a vector of class labels where each of the $5000$ rows in $y$ corresponds to a <b>class label</b> between \"$1$\" to \"$10$\" identifying to which of the $10$ classes an image belongs, i.e. to which number between $0$ to $9$ does the image correspond.\n",
    "\n",
    "\n",
    "* The label \"$0$\" is mapped to the digit \"$10$\" to avoid confusion with indexing) for each sample image.\n",
    "\n",
    "#### So what is this line doing?\n",
    "\n",
    "`np.array([1 if label == i else 0 for label in y])` transforms $y$ from:\n",
    "\n",
    "* a vector of <b>class labels</b> identifying what number the handwritten digit represents;\n",
    "\n",
    "  to\n",
    "  \n",
    "\n",
    "* a vector of <b>binary values</b>, either $0$ or $1$ depending on whether the class label for a particular example matches the class of the particular classifier.  \n",
    "\n",
    "##### An Example\n",
    "\n",
    "* In the first iteration of the `for` we are classifying whether each image IS or is NOT a number \"$1$\"\n",
    "\n",
    "\n",
    "* To enable this classifier, Line 18 will have transformed the $y$ vector so that each class label for each image is now transformed into a binary value identifying simply whether each image:\n",
    "    <br>\n",
    "    <br>\n",
    "\n",
    "    * <b>IS</b> \"$1$\"; or\n",
    "    <br>\n",
    "    <br>\n",
    "\n",
    "    * is <b>NOT</b> \"$1$\".\n",
    "    \n",
    "\n",
    "* If the first sample image is labelled \"$7$\" its corresponding $y$ value will have been transformed from \"$7$\" &rarr; \"$0$\", i.e. because it doesn't belong to the class labelled \"$1$\".\n",
    "\n",
    "\n",
    "* This transformed set of $y$ values is then used throughout the functions to optimise each classifier using the code at line 22."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h) Line 19\n",
    "\n",
    "Flips the `y_i` vector from:\n",
    "\n",
    "* a $1$ row x $5000$ column vector\n",
    "\n",
    "  to \n",
    "    \n",
    "    \n",
    "* a $5000$ row x $1$ column vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (j) Lines 22 and 23\n",
    "\n",
    "#### Line 22\n",
    "\n",
    "Finally, we're using SciPy's newer optimization API to minimize the cost function for each classifier.  The API takes:\n",
    "\n",
    "        fmin = minimize(fun=cost, x0=theta, args=(X, y_i, learning_rate), method='TNC', jac=gradient)\n",
    "\n",
    "\n",
    "1. An objective function, in this case the `cost` function.\n",
    "\n",
    "\n",
    "2. An initial set of parameters, in this case the intial `theta` vector.\n",
    "\n",
    "\n",
    "3. A set of arguments, in this case:\n",
    "\n",
    "    (a) `X`, i.e. the matrix $X$ of each image sample;\n",
    "    \n",
    "    (b) `y_i`, i.e. the vector of binary values corresponding to the particular classifier; and\n",
    "    \n",
    "    (c) the `learning_rate`.\n",
    "\n",
    "3. An optimization method, in this case `TNC`; and\n",
    "\n",
    "\n",
    "4. A jacobian (gradient) function if specified.  \n",
    "\n",
    "#### Line 23\n",
    "\n",
    "The parameters found by the optimization routine for each classifier are then assigned to the parameter array, `all_theta`.  \n",
    "After all iterations `all_theta` will contain $10$ rows x $401$ columns, each row corresponding to the optimised $\\theta$ values for each of the 10 classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line 25\n",
    "\n",
    "* Returns the `all_theta` matrix of optimised parameters for each of the $10$ classifiers.\n",
    "\n",
    "\n",
    "* This matrix is of the dimensions: $10$ rows x $401$ columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 10 - Checking Dimensionality\n",
    "\n",
    "One of the more challenging parts of implementing vectorized code is getting all of the matrix interactions written correctly, so I find it useful to do some sanity checks by looking at the shapes of the arrays / matrices I'm working with and convincing myself that they're sensible.  \n",
    "\n",
    "Let's look at some of the data structures used in the above function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 401), (5000, 1), (401,), (10, 401), 5000, 400)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No. of rows of the X matrix, i.e. 5000\n",
    "rows = data['X'].shape[0]\n",
    "\n",
    "# No. of columns of the X matrix, i.e. 400\n",
    "params = data['X'].shape[1]\n",
    "\n",
    "# The matrix of all theta values for each of the 10 classifiers\n",
    "all_theta = np.zeros((10, params + 1))\n",
    "\n",
    "# The X matrix AFTER the bias unit feature x_0 is added at index 0 of X matrix\n",
    "X = np.insert(data['X'], 0, values=np.ones(rows), axis=1)\n",
    "\n",
    "# The matrix of initial theta values, expanded by +1 to reflect the x_0 feature\n",
    "theta = np.zeros(params + 1)\n",
    "\n",
    "# The $y$ vector for a particular classifier, transformed from a vector of class labels to a vector of binary values\n",
    "y_0 = np.array([1 if label == 0 else 0 for label in data['y']])\n",
    "\n",
    "# Same as above, albeit reshaped from a row vector to a column vector.\n",
    "y_0 = np.reshape(y_0, (rows, 1))\n",
    "\n",
    "X.shape, y_0.shape, theta.shape, all_theta.shape, rows, params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These all appear to make sense.  Note that theta is a one-dimensional array, so when it gets converted to a matrix in the code that computes the gradient, it turns into a (1 X 401) matrix.  Let's also check the class labels in y to make sure they look like what we're expecting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(data['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 11 - Running our Training Function\n",
    "\n",
    "Let's make sure that our training function actually runs, and we get some sensible outputs, before going any further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.70247926e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "        -2.24803608e-10,  2.31962906e-11,  0.00000000e+00],\n",
       "       [-8.96250666e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         7.26120759e-09, -6.19965241e-10,  0.00000000e+00],\n",
       "       [-8.39553327e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "        -7.61695557e-10,  4.64917621e-11,  0.00000000e+00],\n",
       "       ...,\n",
       "       [-7.00832477e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "        -6.92009077e-10,  4.29241521e-11,  0.00000000e+00],\n",
       "       [-7.65188037e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "        -8.09503443e-10,  5.31058807e-11,  0.00000000e+00],\n",
       "       [-6.63412331e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "        -3.49765821e-09,  1.13668504e-10,  0.00000000e+00]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_theta = one_vs_all(data['X'], data['y'], 10, 1)\n",
    "all_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, so the above is a $10$ row by $401$ column matrix of all the optimised $\\theta$ values corresponding to each classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 12 - Predicting our $y$ values and scoring accuracy!\n",
    "\n",
    "We're now ready for the final step - using the trained classifiers to predict a label for each image.  For this step we're going to compute the class probability for each class, for each training instance (using vectorized code of course!) and assign the output class label as the class with the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_all(X, all_theta):\n",
    "    rows = X.shape[0]\n",
    "    params = X.shape[1]\n",
    "    num_labels = all_theta.shape[0]\n",
    "    \n",
    "    # Same as before, insert ones to match the shape\n",
    "    X = np.insert(X, 0, values=np.ones(rows), axis=1)\n",
    "    \n",
    "    # Convert to matrices\n",
    "    X = np.matrix(X)\n",
    "    all_theta = np.matrix(all_theta)\n",
    "    \n",
    "    # Computes the probability that a sample belongs to each of the 10 classes, i.e. probability it is class 1, class 2 etc\n",
    "    h = sigmoid(X * all_theta.T)\n",
    "    \n",
    "    # Create array of the index with the maximum probability\n",
    "    h_argmax = np.argmax(h, axis=1)\n",
    "    \n",
    "    # Because our array was zero-indexed we need to add one for the true label prediction\n",
    "    h_argmax = h_argmax + 1\n",
    "    \n",
    "    return h_argmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intuition - Line by Line Analysis\n",
    "\n",
    "### (a) Line 14\n",
    "\n",
    "* `sigmoid(X * all_theta.T)` multiplies the $5000$ x $401$ dimension $X$ matrix of image samples by the $10$ x $401$ dimension $\\Theta$ matrix of $\\theta$ values for each of the 10 classifiers.  \n",
    "\n",
    "\n",
    "* Returns a $5000$ x $10$ matrix of probabilities where each row represents class probabilities, i.e. % probability an image belongs to class 1, 2, 3, 4, 5, 6, 7, 8, 9, or 10.  Each column in that row is one of those % probabilities, e.g. $h_3^1$ = $P(y = 3)$ for sample 3.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Lines 17 and 20\n",
    "\n",
    "#### Line 17\n",
    "\n",
    "For each row in the `h` matrix, `h_argmax = np.argmax(h, axis=1)` returns the index (i.e. column in that row) of the highest probability that the image belongs to a particular class. \n",
    "\n",
    "#### Line 20\n",
    "\n",
    "Adds $+1$ to each index because our labels array was 1 indexed, not 0 indexed:\n",
    "\n",
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[3],\n",
       "        [2],\n",
       "        [1]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [[0, 1, 64], [3, 45, 1], [12, 3, 5]]\n",
    "a = np.matrix(a)\n",
    "# a ==> matrix([[ 0,  1, 64],\n",
    "#               [ 3, 45,  1],\n",
    "#               [12,  3,  5]])\n",
    "h_argmax = np.argmax(a, axis=1)\n",
    "h_argmax = h_argmax + 1\n",
    "h_argmax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This would indicate image 1 is most likely class 3, image 2 is most likely class 2 and image 3 is most likely class 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 13 - Running our Prediction Function and testing accuacy\n",
    "\n",
    "Now we can use the predict_all function to generate class predictions for each instance and see how well our classifier works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 74.6%\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict_all(data['X'], all_theta)\n",
    "correct = [1 if a == b else 0 for (a, b) in zip(y_pred, data['y'])]\n",
    "accuracy = (sum(map(int, correct)) / float(len(correct)))\n",
    "print('accuracy = {0}%'.format(accuracy * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
