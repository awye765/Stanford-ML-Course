{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5: Neural Network with Forward & Backward Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting the Scene\n",
    "\n",
    "For this exercise we'll:\n",
    "\n",
    "* Again tackle the hand-written digits data set, this time using a feed-forward neural network with backpropagation.  \n",
    "\n",
    "\n",
    "* Implement un-regularized and regularized versions of the neural network cost function and gradient computation via the backpropagation algorithm.\n",
    "\n",
    "\n",
    "* Implement random weight initialization and a method to use the network to make predictions.\n",
    "\n",
    "Since the data set is the same one we used in Exercise 3 from Week 4, we'll re-use the code to load the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': b'MATLAB 5.0 MAT-file, Platform: GLNXA64, Created on: Sun Oct 16 13:09:09 2011',\n",
       " '__version__': '1.0',\n",
       " '__globals__': [],\n",
       " 'X': array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]]),\n",
       " 'y': array([[10],\n",
       "        [10],\n",
       "        [10],\n",
       "        ..., \n",
       "        [ 9],\n",
       "        [ 9],\n",
       "        [ 9]], dtype=uint8)}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = loadmat('ex3data1.mat')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Do some initial analysis!\n",
    "\n",
    "As always, let's prioritise checking the dimensionality of our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 400), (5000, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['X'].shape, data['y'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before with Week 4, this tells us the $X$ matrix of features is $5000$ rows x $400$ columns and that the $y$ vector of labels is $5000$ rows x $1$ column.\n",
    "\n",
    "This is because:\n",
    "\n",
    "* $X$ is a matrix comprising $5000$ example images (the \"<b>Sample Matrix</b>\").\n",
    "\n",
    "\n",
    "* Each of those $5000$ images is itself represented by a $400$ feature dimensional vector, i.e. each row in $X$ represents a single image $x^i$ (each an \"<b>Image Vector</b>\").\n",
    "\n",
    "\n",
    "* Each feature in each Image Vector $x^i$, i.e. from $x_0$, $x_1$, ... $x_{400}$, is a numerical value corresponding to the grayscale intensities of each pixel in each original 20 x 20 pixel image, ranging from between 0 (white) to 1 (black)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 - Plot the Data\n",
    "\n",
    "Same as for Week 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1100dd358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 2))\n",
    "counter = 1\n",
    "for digit in np.random.choice(range(5000), 40, replace = False):\n",
    "    plt.subplot(4, 10, counter)\n",
    "    sub = data['X'][digit].reshape((20, 20), order = 'F')\n",
    "    plt.imshow(sub, cmap = 'Greys')\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    counter +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 - Define our X and y variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're going to need these later (and will use them often), let's create some useful variables up-front."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 400), (5000, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data['X']\n",
    "y = data['y']\n",
    "\n",
    "# Again, let's double check the dimensionality!\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6 - One-Hot Encode y Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're also going to need to one-hot encode our y labels.  One-hot encoding turns a class label (AKA \"Categorical Label\") n (out of k classes) into a vector of length k where index n is \"hot\" (1) while the rest are zero.  \n",
    "\n",
    "This is necessary because the $y$ vector of labels describes the correct label for each image, i.e. one of 0, 1, 2, 3, 4, 5, 6, 7, 8 or 9.\n",
    "\n",
    "Scikit-learn has a built in utility we can use for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y_onehot = encoder.fit_transform(y)\n",
    "y_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([10], dtype=uint8),\n",
       " array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0], y_onehot[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Recall</b> that the dataset's $y$ values are 1 indexed to accomodate the original Matlab exercise per the Coursera course.  Therefore, a \"0\" digit is labelled \"10\"m while digits \"1\" to \"9\" are labeled as \"1\" to \"9\" in their natural order.  \n",
    "\n",
    "Accordingly, as the above demonstrates, the label for index 0 of the $y$ vector is \"10\" (`array([10])`), which in reality corresponds to the label \"0\".  After one-hot encoding, the the equivalent entry in the `y_onehot` vector is a row vector where the first 9 indices are equal to 0 and the 10th indice equal to 1:\n",
    "\n",
    "`array([ 0.,  0.,  0., 0.,  0.,  0.,  0.,  0.,  0.,  1.]))`\n",
    "\n",
    "In this way, we've encoded the label of \"10\" (i.e. \"0\") using one-hot encoding.\n",
    "\n",
    "<b>Useful Resource:</b>\n",
    "    \n",
    "- https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7 - Understand the Desired Neural Network Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network we're going to build for this exercise has:\n",
    "\n",
    "1. An input layer matching the size of our features + bias unit, i.e. 401.  This represents:\n",
    "\n",
    "    (a) 400 features corresponding to the greyscale value of each pixel in each 20 x 20 pixel image; \n",
    "    \n",
    "    (b) + the bias unit.\n",
    "\n",
    "\n",
    "2. A hidden layer with 25 units (26 with the bias unit).\n",
    "\n",
    "\n",
    "3. An output layer with 10 units corresponding to our one-hot encoding for the class labels.  \n",
    "\n",
    "<p align = \"center\">\n",
    "<img src=\"../Images\\NNExStructure.PNG\" width=60%>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8 - Define the Forward Propagation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first piece we need to implement is a cost function to evaluate the loss for a given set of network parameters.  The source mathematical function is in the exercise text (and looks pretty intimidating).  Here are the functions required to compute the cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) Defining the Sigmoid Function\n",
    "\n",
    "Same as always:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Defining the Feed Forward Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagate(X, theta1, theta2):\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    a1 = np.insert(X, 0, values=np.ones(m), axis=1)\n",
    "    z2 = a1 * theta1.T\n",
    "    a2 = np.insert(sigmoid(z2), 0, values=np.ones(m), axis=1)\n",
    "    z3 = a2 * theta2.T\n",
    "    h = sigmoid(z3)\n",
    "    \n",
    "    return a1, z2, a2, z3, h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that:\n",
    "\n",
    "* $a1$ is the matrix of activation values in layer 1, i.e. the features.\n",
    "\n",
    "\n",
    "* $z2$ is the matrix of input values from layer 1 to layer 2, i.e. the layer 1 activation values matrix x the layer 1 theta matrix.\n",
    "\n",
    "\n",
    "* $a2$ is the matrix of activation values in layer 2, i.e. the result of sigmoiding the values from $z2$.\n",
    "\n",
    "\n",
    "* $z3$ is the matrix of input values from layer 2 to layer 3, i.e. the layer 2 activation values matrix x the layer 2 theta matrix.\n",
    "\n",
    "\n",
    "* $h$ is the matrix of output values in layer 3, i.e. the result of sigmoiding the values form $z3$.\n",
    "\n",
    "Altogether, this forward propagates values from the first layer through to the final layer and completes the <b>forward pass</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) Defining the Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(params, input_size, hidden_size, num_labels, X, y, learning_rate):\n",
    "    m = X.shape[0]\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    \n",
    "    # reshape the parameter array into parameter matrices for each layer\n",
    "    theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "    theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "    \n",
    "    # run the feed-forward pass\n",
    "    a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
    "    \n",
    "    # compute the cost\n",
    "    J = 0\n",
    "    for i in range(m):\n",
    "        first_term = np.multiply(-y[i,:], np.log(h[i,:]))\n",
    "        second_term = np.multiply((1 - y[i,:]), np.log(1 - h[i,:]))\n",
    "        J += np.sum(first_term - second_term)\n",
    "    \n",
    "    J = J / m\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d) Checking our Forward Propagation\n",
    "\n",
    "Recall again that the forward-propagate function computes the hypothesis for each training instance given the current parameters.  \n",
    "\n",
    "Therefore, it's <b>output shape should match the same of our one-hot encoding for y</b>.  \n",
    "\n",
    "We can test this real quick to convince ourselves that it's working as expected (the intermediate steps are also returned as these will be useful later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25, 401), (10, 26))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initial setup\n",
    "input_size = 400\n",
    "hidden_size = 25\n",
    "num_labels = 10\n",
    "learning_rate = 1\n",
    "\n",
    "# randomly initialize a parameter array of the size of the full network's parameters\n",
    "params = (np.random.random(size=hidden_size * (input_size + 1) + num_labels * (hidden_size + 1)) - 0.5) * 0.25\n",
    "\n",
    "m = X.shape[0]\n",
    "X = np.matrix(X)\n",
    "y = np.matrix(y)\n",
    "\n",
    "# unravel the parameter array into parameter matrices for each layer\n",
    "theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "\n",
    "theta1.shape, theta2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 401), (5000, 25), (5000, 26), (5000, 10), (5000, 10))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
    "a1.shape, z2.shape, a2.shape, z3.shape, h.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (e) Running the Cost Function\n",
    "\n",
    "The cost function, after computing the hypothesis matrix $h$, applies the cost equation to compute the total error between $y$ and $h$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0379168093287054"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost(params, input_size, hidden_size, num_labels, X, y_onehot, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Step 9 - Regularise the Cost Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next step, per the original exercise materials, is to add regularization to the cost function.  Here's the revised cost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(params, input_size, hidden_size, num_labels, X, y, learning_rate):\n",
    "    m = X.shape[0]\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    \n",
    "    # reshape the parameter array into parameter matrices for each layer\n",
    "    theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "    theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "    \n",
    "    # run the feed-forward pass\n",
    "    a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
    "    \n",
    "    # compute the cost\n",
    "    J = 0\n",
    "    for i in range(m):\n",
    "        first_term = np.multiply(-y[i,:], np.log(h[i,:]))\n",
    "        second_term = np.multiply((1 - y[i,:]), np.log(1 - h[i,:]))\n",
    "        J += np.sum(first_term - second_term)\n",
    "    \n",
    "    J = J / m\n",
    "    \n",
    "    # add the cost regularization term\n",
    "    J += (float(learning_rate) / (2 * m)) * (np.sum(np.power(theta1[:,1:], 2)) + np.sum(np.power(theta2[:,1:], 2)))\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 10 - Define the Backpropagation Function\n",
    "\n",
    "Next up is the backpropagation algorithm.  Backpropagation computes the parameter updates that will reduce the error of the network on the training data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) Define the Sigmoid Gradient Function\n",
    "\n",
    "The first thing we need is a function that computes the gradient of the sigmoid function we created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_gradient(z):\n",
    "    return np.multiply(sigmoid(z), (1 - sigmoid(z)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Define the Backward Pass Function\n",
    "\n",
    "Now we're ready to implement backpropagation to compute the gradients.  \n",
    "\n",
    "Since the computations required for backpropagation are a superset of those required in the cost function, we're actually going to extend the cost function to also perform backpropagation and return both the cost and the gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop(params, input_size, hidden_size, num_labels, X, y, learning_rate):\n",
    "    m = X.shape[0]\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    \n",
    "    # reshape the parameter array into parameter matrices for each layer\n",
    "    theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "    theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "    \n",
    "    # run the feed-forward pass\n",
    "    a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
    "    \n",
    "    # initializations\n",
    "    J = 0\n",
    "    delta1 = np.zeros(theta1.shape)  # (25, 401)\n",
    "    delta2 = np.zeros(theta2.shape)  # (10, 26)\n",
    "    \n",
    "    # compute the cost\n",
    "    for i in range(m):\n",
    "        first_term = np.multiply(-y[i,:], np.log(h[i,:]))\n",
    "        second_term = np.multiply((1 - y[i,:]), np.log(1 - h[i,:]))\n",
    "        J += np.sum(first_term - second_term)\n",
    "    \n",
    "    J = J / m\n",
    "    \n",
    "    # add the cost regularization term\n",
    "    J += (float(learning_rate) / (2 * m)) * (np.sum(np.power(theta1[:,1:], 2)) + np.sum(np.power(theta2[:,1:], 2)))\n",
    "    \n",
    "    # perform backpropagation\n",
    "    for t in range(m):\n",
    "        a1t = a1[t,:]  # (1, 401)\n",
    "        z2t = z2[t,:]  # (1, 25)\n",
    "        a2t = a2[t,:]  # (1, 26)\n",
    "        ht = h[t,:]    # (1, 10)\n",
    "        yt = y[t,:]    # (1, 10)\n",
    "        \n",
    "        d3t = ht - yt  # (1, 10)\n",
    "        \n",
    "        z2t = np.insert(z2t, 0, values=np.ones(1))  # (1, 26)\n",
    "        d2t = np.multiply((theta2.T * d3t.T).T, sigmoid_gradient(z2t))  # (1, 26)\n",
    "        \n",
    "        delta1 = delta1 + (d2t[:,1:]).T * a1t\n",
    "        delta2 = delta2 + d3t.T * a2t\n",
    "        \n",
    "    delta1 = delta1 / m\n",
    "    delta2 = delta2 / m\n",
    "    \n",
    "    # unravel the gradient matrices into a single array\n",
    "    grad = np.concatenate((np.ravel(delta1), np.ravel(delta2)))\n",
    "    \n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hardest part of the backprop computation (other than understanding WHY we're doing all these calculations) is getting the matrix dimensions right.  \n",
    "\n",
    "By the way, if you find it confusing when to use A * B vs. np.multiply(A, B), you're not alone.  \n",
    "\n",
    "Basically the former is a matrix multiplication and the latter is an element-wise multiplication (unless A or B is a scalar value, in which case it doesn't matter).  \n",
    "\n",
    "Anyway, let's test it out to make sure the function returns what we're expecting it to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.0432138937834665, (10285,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J, grad = backprop(params, input_size, hidden_size, num_labels, X, y_onehot, learning_rate)\n",
    "J, grad.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have one more modification to make to the backprop function - adding regularization to the gradient calculations.  The final regularized version is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop(params, input_size, hidden_size, num_labels, X, y, learning_rate):\n",
    "    m = X.shape[0]\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    \n",
    "    # reshape the parameter array into parameter matrices for each layer\n",
    "    theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "    theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "    \n",
    "    # run the feed-forward pass\n",
    "    a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
    "    \n",
    "    # initializations\n",
    "    J = 0\n",
    "    delta1 = np.zeros(theta1.shape)  # (25, 401)\n",
    "    delta2 = np.zeros(theta2.shape)  # (10, 26)\n",
    "    \n",
    "    # compute the cost\n",
    "    for i in range(m):\n",
    "        first_term = np.multiply(-y[i,:], np.log(h[i,:]))\n",
    "        second_term = np.multiply((1 - y[i,:]), np.log(1 - h[i,:]))\n",
    "        J += np.sum(first_term - second_term)\n",
    "    \n",
    "    J = J / m\n",
    "    \n",
    "    # add the cost regularization term\n",
    "    J += (float(learning_rate) / (2 * m)) * (np.sum(np.power(theta1[:,1:], 2)) + np.sum(np.power(theta2[:,1:], 2)))\n",
    "    \n",
    "    # perform backpropagation\n",
    "    for t in range(m):\n",
    "        a1t = a1[t,:]  # (1, 401)\n",
    "        z2t = z2[t,:]  # (1, 25)\n",
    "        a2t = a2[t,:]  # (1, 26)\n",
    "        ht = h[t,:]  # (1, 10)\n",
    "        yt = y[t,:]  # (1, 10)\n",
    "        \n",
    "        d3t = ht - yt  # (1, 10)\n",
    "        \n",
    "        z2t = np.insert(z2t, 0, values=np.ones(1))  # (1, 26)\n",
    "        d2t = np.multiply((theta2.T * d3t.T).T, sigmoid_gradient(z2t))  # (1, 26)\n",
    "        \n",
    "        delta1 = delta1 + (d2t[:,1:]).T * a1t\n",
    "        delta2 = delta2 + d3t.T * a2t\n",
    "        \n",
    "    delta1 = delta1 / m\n",
    "    delta2 = delta2 / m\n",
    "    \n",
    "    # add the gradient regularization term\n",
    "    delta1[:,1:] = delta1[:,1:] + (theta1[:,1:] * learning_rate) / m\n",
    "    delta2[:,1:] = delta2[:,1:] + (theta2[:,1:] * learning_rate) / m\n",
    "    \n",
    "    # unravel the gradient matrices into a single array\n",
    "    grad = np.concatenate((np.ravel(delta1), np.ravel(delta2)))\n",
    "    \n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.0432138937834665, (10285,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J, grad = backprop(params, input_size, hidden_size, num_labels, X, y_onehot, learning_rate)\n",
    "J, grad.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 11 - Training the Full Algorithm\n",
    "\n",
    "We're finally ready to train our network and use it to make predictions.  This is roughly similar to the previous exercise with multi-class logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: 0.3372681436129189\n",
       "     jac: array([  2.42697573e-04,  -2.00863674e-08,  -6.71899421e-07, ...,\n",
       "        -4.62189962e-06,  -3.33073418e-06,   5.12740489e-05])\n",
       " message: 'Max. number of function evaluations reached'\n",
       "    nfev: 250\n",
       "     nit: 24\n",
       "  status: 3\n",
       " success: False\n",
       "       x: array([  9.56818726e-01,  -1.00431837e-04,  -3.35949711e-03, ...,\n",
       "         6.79413349e-02,  -1.57427766e+00,  -7.92510768e-02])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# minimize the objective function\n",
    "fmin = minimize(fun=backprop, x0=params, args=(input_size, hidden_size, num_labels, X, y_onehot, learning_rate), \n",
    "                method='TNC', jac=True, options={'maxiter': 250})\n",
    "fmin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We put a bound on the number of iterations since the objective function is not likely to completely converge.  Our total cost has dropped below 0.5 though so that's a good indicator that the algorithm is working.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 12 - Checking Accuracy\n",
    "\n",
    "Let's use the parameters it found and forward-propagate them through the network to get some predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10],\n",
       "       [10],\n",
       "       [10],\n",
       "       ..., \n",
       "       [ 9],\n",
       "       [ 9],\n",
       "       [ 9]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.matrix(X)\n",
    "theta1 = np.matrix(np.reshape(fmin.x[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "theta2 = np.matrix(np.reshape(fmin.x[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "\n",
    "a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
    "y_pred = np.array(np.argmax(h, axis=1) + 1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can compute the accuracy to see how well our trained network is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 99.22%\n"
     ]
    }
   ],
   "source": [
    "correct = [1 if a == b else 0 for (a, b) in zip(y_pred, y)]\n",
    "accuracy = (sum(map(int, correct)) / float(len(correct)))\n",
    "print('accuracy = {0}%'.format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we're done!  We've successfully implemented a rudimentary feed-forward neural network with backpropagation and used it to classify images of handwritten digits.  In the next exercise we'll look at another power supervised learning algorithm, support vector machines."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
